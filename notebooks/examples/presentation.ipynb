{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93fdd204",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"../../\"))\n",
    "sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "685e808f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(tuner):\n",
    "    print(\"Final prompt:\", tuner.final_prompt)\n",
    "    print(\"Start prompt metric: \", tuner.init_metric)\n",
    "    print(\"Final prompt metric: \", tuner.final_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bb6438",
   "metadata": {},
   "source": [
    "# Презентация PromptTuner - автопромптинг ассистента\n",
    "\n",
    "Точка входа - ассистент. Он оптимизирует стартовый промпт.\n",
    "\n",
    "Производится оптимизация промпта под переданный датасет (разбивается на train и validation), после чего благодаря заранее заданным мета-шаблонам вычислются метрики промптов на исходном датасете. Мета-шаблон можно посмотреть, вызвав соответствующий геттер ассистента."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "395e5daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 07-01 20:03:14 config.py:1865] Casting torch.bfloat16 to torch.float16.\n",
      "INFO 07-01 20:03:23 config.py:350] This model supports multiple tasks: {'embedding', 'generate'}. Defaulting to 'generate'.\n",
      "INFO 07-01 20:03:23 llm_engine.py:249] Initializing an LLM engine (v0.6.4.post1) with config: model='t-tech/T-lite-it-1.0', speculative_config=None, tokenizer='t-tech/T-lite-it-1.0', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=32768, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=t-tech/T-lite-it-1.0, num_scheduler_steps=1, chunked_prefill_enabled=False multi_step_stream_outputs=True, enable_prefix_caching=False, use_async_output_proc=True, use_cached_outputs=False, chat_template_text_format=string, mm_processor_kwargs=None, pooler_config=None)\n",
      "INFO 07-01 20:03:24 selector.py:261] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\n",
      "INFO 07-01 20:03:24 selector.py:144] Using XFormers backend.\n",
      "INFO 07-01 20:03:25 model_runner.py:1072] Starting to load model t-tech/T-lite-it-1.0...\n",
      "INFO 07-01 20:03:26 weight_utils.py:243] Using model weights format ['*.safetensors']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fd299dd90414d9c8fcff37699e8d84c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 07-01 20:03:31 model_runner.py:1077] Loading model weights took 14.2426 GB\n",
      "INFO 07-01 20:03:37 worker.py:232] Memory profiling results: total_gpu_memory=31.74GiB initial_memory_usage=14.66GiB peak_torch_memory=18.59GiB memory_usage_post_profile=14.69GiB non_torch_memory=0.44GiB kv_cache_size=9.53GiB gpu_memory_utilization=0.90\n",
      "INFO 07-01 20:03:38 gpu_executor.py:113] # GPU blocks: 11154, # CPU blocks: 4681\n",
      "INFO 07-01 20:03:38 gpu_executor.py:117] Maximum concurrency for 32768 tokens per request: 5.45x\n",
      "INFO 07-01 20:03:42 model_runner.py:1400] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 07-01 20:03:42 model_runner.py:1404] If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 07-01 20:04:06 model_runner.py:1518] Graph capturing finished in 24 secs, took 0.80 GiB\n"
     ]
    }
   ],
   "source": [
    "from coolprompt.assistant import PromptTuner\n",
    "tuner = PromptTuner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfa4997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{PROMPT}\n",
      "\n",
      "### HARD CONSTRAINTS ###\n",
      "This is an automated evaluation. Your output will be parsed by a script. Any deviation from the required format will result in failure.\n",
      "\n",
      "1. OUTPUT FORMAT:\n",
      "   - Output ONLY the final answer in the format: `<ans>LABEL</ans>`\n",
      "   - LABEL MUST be EXACTLY one item from the list: [{LABELS}]\n",
      "    - DO NOT include any explanation, reasoning, or extra text.\n",
      "    - DO NOT include any meta-level commentary (e.g., \"Sure\", \"Here is your answer\", \"Let's tackle this\", \"To answer this question\", etc).\n",
      "    - DO NOT modify the tag or the label format.\n",
      "    - DO NOT repeat the answer or output multiple <ans> tags.\n",
      "\n",
      "2. STOP CONDITION:\n",
      "    - IMMEDIATELY stop generating after `</ans>`.\n",
      "    - DO NOT output anything after `</ans>`.\n",
      "\n",
      "3. FAILURE CONDITION:\n",
      "    - If you break any of the above constraints, the output will be considered INVALID and REJECTED.\n",
      "\n",
      "4. FORMAT EXAMPLE:\n",
      "    1. Labels are [(A), (B), (C)] and you chose first answer  \n",
      "       Output will be: <ans>(A)</ans>\n",
      "    2. Labels are [A, B, C] and you chose the first answer  \n",
      "       Output will be: <ans>A</ans>\n",
      "\n",
      "### INPUT ###\n",
      "{INPUT}\n",
      "\n",
      "### RESPONSE ###\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tuner.get_task_prompt_template(task='classification', method='hype'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fe7e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{PROMPT}\n",
      "\n",
      "Generate the final answer bracketed with <ans> and </ans>.\n",
      "\n",
      "INPUT:\n",
      "{INPUT}\n",
      "\n",
      "RESPONSE:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tuner.get_task_prompt_template(task='generation', method='distill'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ceab957",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.43s/it, est. speed input: 175.14 toks/s, output: 39.93 toks/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Write an essay about autumn, focusing on the changes in nature, the emotions it evokes, and the cultural significance of the season. Use descriptive language and provide examples from literature, art, or personal experiences to support your points.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Запуск метода hype без датасета\n",
    "tuner.run(start_prompt=\"Write an essay about autumn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a1649c",
   "metadata": {},
   "source": [
    "Ассистент в режиме оптимизации под датасет может решать одну из двух задач: классификацию или генерацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "187d5fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration stanfordnlp--sst2-c614fb49d6bf6d65\n",
      "Reusing dataset parquet (/home/sitkina-alena/.cache/huggingface/datasets/stanfordnlp___parquet/stanfordnlp--sst2-c614fb49d6bf6d65/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3696aea91fc64626901155e44d56939c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Классификация\n",
    "sst2 = load_dataset(\"stanfordnlp/sst2\")\n",
    "class_dataset = sst2['train']['sentence'][:100]\n",
    "class_targets = sst2['train']['label'][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2095694",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration stanfordnlp--sst2-c614fb49d6bf6d65\n",
      "Reusing dataset parquet (/home/sitkina-alena/.cache/huggingface/datasets/stanfordnlp___parquet/stanfordnlp--sst2-c614fb49d6bf6d65/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64f32019ff9242998f1bd8ff6d620fd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/sitkina-alena/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--f1/34c46321f42186df33a6260966e34a368f14868d9cc2ba47d142112e2800d233 (last modified on Mon Jun 30 17:15:59 2025) since it couldn't be found locally at evaluate-metric--f1, or remotely on the Hugging Face Hub.\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s, est. speed input: 350.60 toks/s, output: 38.01 toks/s]\n",
      "Processed prompts: 100%|██████████| 100/100 [01:42<00:00,  1.02s/it, est. speed input: 293.02 toks/s, output: 46.89 toks/s]\n",
      "Processed prompts: 100%|██████████| 100/100 [00:06<00:00, 16.65it/s, est. speed input: 5170.06 toks/s, output: 133.22 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final prompt: Please provide a sentence and classify its sentiment as positive, negative, or neutral.\n",
      "Start prompt metric:  0.6364983164983165\n",
      "Final prompt metric:  0.8899889988998899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tuner.run(\n",
    "    start_prompt=\"Classify sentence sentiment\",\n",
    "    task=\"classification\",\n",
    "    dataset=class_dataset,\n",
    "    target=class_targets,\n",
    "    metric=\"f1\"\n",
    ")\n",
    "\n",
    "print_results(tuner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6790e788",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/sitkina-\n",
      "[nltk_data]     alena/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/sitkina-\n",
      "[nltk_data]     alena/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/sitkina-\n",
      "[nltk_data]     alena/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.30it/s, est. speed input: 326.56 toks/s, output: 37.88 toks/s]\n",
      "Processed prompts: 100%|██████████| 200/200 [00:18<00:00, 11.02it/s, est. speed input: 4206.55 toks/s, output: 275.33 toks/s]\n",
      "Processed prompts: 100%|██████████| 200/200 [00:25<00:00,  7.90it/s, est. speed input: 3109.76 toks/s, output: 255.11 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final prompt: Please provide a concise summary of the text, focusing on the main points and key details.\n",
      "Start prompt metric:  0.25465833610131716\n",
      "Final prompt metric:  0.3145034036877276\n"
     ]
    }
   ],
   "source": [
    "# Генерация\n",
    "samsum = load_dataset(\"knkarthick/samsum\")\n",
    "gen_dataset = samsum['train']['dialogue'][:200]\n",
    "gen_targets = samsum['train']['summary'][:200]\n",
    "\n",
    "tuner.run(\n",
    "    start_prompt=\"Summarize the text\",\n",
    "    task=\"generation\",\n",
    "    dataset=gen_dataset,\n",
    "    target=gen_targets,\n",
    "    metric=\"meteor\"\n",
    ")\n",
    "\n",
    "print_results(tuner)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4f32b7",
   "metadata": {},
   "source": [
    "## Language model\n",
    "\n",
    "При инициализации юзер может подать уже имеющуюся LLM-ку, \n",
    "\n",
    "или инициализировать асситента без аргументов, и будет использована дефолтная модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53824d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Write a descriptive paragraph about the colors of autumn, focusing on the vibrant hues of red, orange, and yellow that characterize this season. Include sensory details to help the reader imagine the scene.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "llm = Ollama(model=\"llama2\")\n",
    "\n",
    "tuner_with_custom_llm = PromptTuner(model=llm)\n",
    "tuner_with_custom_llm.run(start_prompt=\"Write an essay about autumn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea23300",
   "metadata": {},
   "source": [
    "Доступные модели и их провайдеры: https://python.langchain.com/docs/integrations/llms/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611f8079",
   "metadata": {},
   "source": [
    "## Оптимизатор\n",
    "\n",
    "Фреймворк поддерживает несколько различных алгоритмов оптимизации промптов\n",
    "\n",
    "- HyPE\n",
    "- DistillPrompt\n",
    "- ReflectivePrompt\n",
    "\n",
    "Выбор алгоритма производится в параметрах метода run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456a7661",
   "metadata": {},
   "source": [
    "### HyPE\n",
    "Мы уже видели его работу до этого - используя заранее заданную системную инструкцию просит модель оптимизировать поданный промпт. оптимизация происходит в одну итерацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12428e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.36it/s, est. speed input: 338.07 toks/s, output: 36.66 toks/s]\n",
      "Processed prompts: 100%|██████████| 100/100 [01:42<00:00,  1.02s/it, est. speed input: 293.36 toks/s, output: 46.94 toks/s]\n",
      "Processed prompts: 100%|██████████| 100/100 [00:05<00:00, 16.96it/s, est. speed input: 5265.82 toks/s, output: 135.69 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final prompt: Please provide a sentence and classify its sentiment as positive, negative, or neutral.\n",
      "Start prompt metric:  0.6364983164983165\n",
      "Final prompt metric:  0.8899889988998899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tuner.run(\n",
    "    start_prompt=\"Classify sentence sentiment\",\n",
    "    task=\"classification\",\n",
    "    dataset=class_dataset,\n",
    "    target=class_targets,\n",
    ")\n",
    "\n",
    "print_results(tuner)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a7468c",
   "metadata": {},
   "source": [
    "### DistillPrompt\n",
    "\n",
    "Метод автопромптинга, основанный на последовательной дистилляции и агрегации знаний LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12d1a010",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/sitkina-alena/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--f1/34c46321f42186df33a6260966e34a368f14868d9cc2ba47d142112e2800d233 (last modified on Mon Jun 30 17:15:59 2025) since it couldn't be found locally at evaluate-metric--f1, or remotely on the Hugging Face Hub.\n",
      "[2025-07-01 20:04:49,726] - Starting DistillPrompt optimization...\n",
      "Processed prompts: 100%|██████████| 15/15 [02:04<00:00,  8.29s/it, est. speed input: 5.51 toks/s, output: 332.05 toks/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s][2025-07-01 20:06:54,149] - Starting round 0\n",
      "Processed prompts: 100%|██████████| 4/4 [00:01<00:00,  2.83it/s, est. speed input: 317.63 toks/s, output: 101.38 toks/s]\n",
      "Processed prompts: 100%|██████████| 15/15 [00:00<00:00, 30.63it/s, est. speed input: 2626.59 toks/s, output: 245.08 toks/s]\n",
      "Processed prompts: 100%|██████████| 15/15 [00:00<00:00, 24.69it/s, est. speed input: 1876.73 toks/s, output: 209.80 toks/s]\n",
      "Processed prompts: 100%|██████████| 15/15 [01:50<00:00,  7.36s/it, est. speed input: 8.11 toks/s, output: 181.85 toks/s]\n",
      "Processed prompts: 100%|██████████| 15/15 [00:00<00:00, 38.25it/s, est. speed input: 2170.63 toks/s, output: 306.06 toks/s]\n",
      "Processed prompts: 100%|██████████| 4/4 [01:44<00:00, 26.22s/it, est. speed input: 10.11 toks/s, output: 83.18 toks/s]\n",
      "Processed prompts: 100%|██████████| 15/15 [01:37<00:00,  6.49s/it, est. speed input: 40.64 toks/s, output: 47.65 toks/s]\n",
      "Processed prompts: 100%|██████████| 15/15 [00:00<00:00, 33.18it/s, est. speed input: 2579.75 toks/s, output: 265.48 toks/s]\n",
      "Processed prompts: 100%|██████████| 15/15 [01:51<00:00,  7.43s/it, est. speed input: 28.22 toks/s, output: 180.51 toks/s]\n",
      "Processed prompts: 100%|██████████| 15/15 [01:52<00:00,  7.47s/it, est. speed input: 41.86 toks/s, output: 179.64 toks/s]\n",
      "Processed prompts: 100%|██████████| 4/4 [01:37<00:00, 24.31s/it, est. speed input: 11.08 toks/s, output: 43.36 toks/s]\n",
      "Processed prompts: 100%|██████████| 15/15 [01:36<00:00,  6.46s/it, est. speed input: 18.08 toks/s, output: 45.57 toks/s]\n",
      "Processed prompts: 100%|██████████| 15/15 [00:00<00:00, 33.04it/s, est. speed input: 2569.59 toks/s, output: 264.44 toks/s]\n",
      "Processed prompts: 100%|██████████| 15/15 [01:58<00:00,  7.92s/it, est. speed input: 19.53 toks/s, output: 291.28 toks/s]\n",
      "Processed prompts: 100%|██████████| 15/15 [01:46<00:00,  7.07s/it, est. speed input: 13.40 toks/s, output: 114.43 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.54s/it, est. speed input: 149.59 toks/s, output: 40.26 toks/s]\n",
      "Processed prompts: 100%|██████████| 15/15 [01:46<00:00,  7.08s/it, est. speed input: 19.17 toks/s, output: 115.32 toks/s]\n",
      "Processed prompts: 100%|██████████| 3/3 [01:37<00:00, 32.40s/it, est. speed input: 3.46 toks/s, output: 44.74 toks/s]\n",
      "Processed prompts: 100%|██████████| 15/15 [02:51<00:00, 11.45s/it, est. speed input: 353.00 toks/s, output: 280.19 toks/s]\n",
      "Processed prompts: 100%|██████████| 15/15 [00:07<00:00,  1.96it/s, est. speed input: 460.88 toks/s, output: 387.32 toks/s]\n",
      "Processed prompts: 100%|██████████| 15/15 [00:06<00:00,  2.42it/s, est. speed input: 469.53 toks/s, output: 303.43 toks/s]\n",
      "[2025-07-01 20:29:25,224] - Best candidate score in round 0: 0.9321266968325792\n",
      "[2025-07-01 20:29:25,225] - Best candidate prompt: Classify the sentiment of a given sentence as positive, negative, or neutral.\n",
      "100%|██████████| 1/1 [22:31<00:00, 1351.08s/it]\n",
      "Processed prompts: 100%|██████████| 5/5 [00:00<00:00, 17.36it/s, est. speed input: 1010.82 toks/s, output: 138.93 toks/s]\n",
      "[2025-07-01 20:29:25,530] - Final best prompt score on validation: 0.7619047619047619\n",
      "[2025-07-01 20:29:25,531] - Final best prompt: Classify the sentiment of a given sentence as positive, negative, or neutral.\n",
      "Processed prompts: 100%|██████████| 20/20 [02:05<00:00,  6.28s/it, est. speed input: 7.35 toks/s, output: 345.64 toks/s] \n",
      "Processed prompts: 100%|██████████| 20/20 [00:00<00:00, 44.52it/s, est. speed input: 2543.20 toks/s, output: 356.29 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final prompt: Classify the sentiment of a given sentence as positive, negative, or neutral.\n",
      "Start prompt metric:  0.21031746031746032\n",
      "Final prompt metric:  0.8465473145780051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tuner.run(\n",
    "    start_prompt=\"Classify sentence sentiment\",\n",
    "    task='classification',\n",
    "    dataset=class_dataset[:20],\n",
    "    target=class_targets[:20],\n",
    "    method='distill',\n",
    "    use_cache=False,\n",
    "    num_epochs=1\n",
    ")\n",
    "\n",
    "print_results(tuner)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77dad7ef",
   "metadata": {},
   "source": [
    "### ReflectivePrompt\n",
    "\n",
    "Метод автопромптинга на основе эволюционных алгоритмов, использующий подход рефлексивной эволюции для более точного и расширенного поиска оптимальных промптов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58afa175",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-07-01 15:00:27,601] - Initializing population...\n",
      "Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.61s/it, est. speed input: 49.72 toks/s, output: 40.39 toks/s]\n",
      "[2025-07-01 15:00:29,225] - Evaluating population...\n",
      "Processed prompts: 100%|██████████| 75/75 [02:46<00:00,  2.22s/it, est. speed input: 23.17 toks/s, output: 589.40 toks/s]  \n",
      "Processed prompts: 100%|██████████| 75/75 [03:06<00:00,  2.49s/it, est. speed input: 19.86 toks/s, output: 677.03 toks/s] \n",
      "Processed prompts:  39%|███▊      | 29/75 [00:31<00:51,  1.12s/it, est. speed input: 51.55 toks/s, output: 290.76 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 07-01 15:10:47 scheduler.py:1481] Sequence group 225 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 75/75 [04:44<00:00,  3.80s/it, est. speed input: 13.82 toks/s, output: 678.14 toks/s]\n",
      "Processed prompts: 100%|██████████| 75/75 [04:26<00:00,  3.56s/it, est. speed input: 13.91 toks/s, output: 649.55 toks/s]\n",
      "Processed prompts: 100%|██████████| 75/75 [04:08<00:00,  3.31s/it, est. speed input: 16.17 toks/s, output: 674.25 toks/s]\n",
      "Processed prompts: 100%|██████████| 4/4 [00:00<00:00,  6.14it/s, est. speed input: 900.10 toks/s, output: 84.48 toks/s]\n",
      "Processed prompts: 100%|██████████| 4/4 [01:43<00:00, 25.92s/it, est. speed input: 4.06 toks/s, output: 77.75 toks/s]  \n",
      "[2025-07-01 15:21:27,391] - Evaluating population...\n",
      "Processed prompts: 100%|██████████| 75/75 [01:51<00:00,  1.49s/it, est. speed input: 29.15 toks/s, output: 196.48 toks/s]  \n",
      "Processed prompts: 100%|██████████| 75/75 [01:47<00:00,  1.43s/it, est. speed input: 40.98 toks/s, output: 117.55 toks/s]  \n",
      "Processed prompts: 100%|██████████| 75/75 [01:37<00:00,  1.30s/it, est. speed input: 33.42 toks/s, output: 51.93 toks/s]   \n",
      "Processed prompts: 100%|██████████| 75/75 [00:01<00:00, 43.99it/s, est. speed input: 2837.49 toks/s, output: 540.86 toks/s]\n",
      "[2025-07-01 15:26:45,861] - Iteration 0\n",
      "                Elitist (0.959971535314001):\n",
      "                Classify the sentiment of the given text into one of the following categories: positive, negative, or neutral.\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.85it/s, est. speed input: 269.25 toks/s, output: 37.14 toks/s]\n",
      "Processed prompts: 100%|██████████| 4/4 [00:01<00:00,  2.67it/s, est. speed input: 302.13 toks/s, output: 147.05 toks/s]\n",
      "[2025-07-01 15:26:47,909] - Evaluating population...\n",
      "Processed prompts: 100%|██████████| 75/75 [01:54<00:00,  1.53s/it, est. speed input: 59.25 toks/s, output: 220.64 toks/s]  \n",
      "Processed prompts: 100%|██████████| 75/75 [01:55<00:00,  1.53s/it, est. speed input: 58.97 toks/s, output: 219.60 toks/s]  \n",
      "Processed prompts: 100%|██████████| 75/75 [01:54<00:00,  1.53s/it, est. speed input: 59.15 toks/s, output: 220.28 toks/s]  \n",
      "Processed prompts: 100%|██████████| 75/75 [01:54<00:00,  1.53s/it, est. speed input: 59.22 toks/s, output: 220.52 toks/s]  \n",
      "[2025-07-01 15:34:27,161] - Iteration 0\n",
      "                Elitist (0.959971535314001):\n",
      "                Classify the sentiment of the given text into one of the following categories: positive, negative, or neutral.\n",
      "[2025-07-01 15:34:27,162] - Iteration 0 finished...\n",
      "[2025-07-01 15:34:27,163] - Best score: 0.959971535314001\n",
      "Processed prompts: 100%|██████████| 4/4 [00:01<00:00,  2.35it/s, est. speed input: 382.87 toks/s, output: 62.24 toks/s]\n",
      "Processed prompts: 100%|██████████| 4/4 [00:01<00:00,  2.62it/s, est. speed input: 323.45 toks/s, output: 133.18 toks/s]\n",
      "[2025-07-01 15:34:30,410] - Evaluating population...\n",
      "Processed prompts: 100%|██████████| 75/75 [00:09<00:00,  8.15it/s, est. speed input: 696.99 toks/s, output: 682.64 toks/s]\n",
      "Processed prompts: 100%|██████████| 75/75 [00:09<00:00,  8.16it/s, est. speed input: 697.43 toks/s, output: 683.07 toks/s]\n",
      "Processed prompts: 100%|██████████| 75/75 [00:01<00:00, 41.23it/s, est. speed input: 3566.85 toks/s, output: 345.30 toks/s]\n",
      "Processed prompts: 100%|██████████| 75/75 [00:09<00:00,  8.15it/s, est. speed input: 696.73 toks/s, output: 682.39 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.76it/s, est. speed input: 291.13 toks/s, output: 37.05 toks/s]\n",
      "Processed prompts: 100%|██████████| 4/4 [00:01<00:00,  3.95it/s, est. speed input: 449.97 toks/s, output: 142.09 toks/s]\n",
      "[2025-07-01 15:35:01,687] - Evaluating population...\n",
      "Processed prompts: 100%|██████████| 75/75 [00:05<00:00, 14.29it/s, est. speed input: 1035.83 toks/s, output: 760.15 toks/s]\n",
      "Processed prompts: 100%|██████████| 75/75 [00:05<00:00, 14.23it/s, est. speed input: 1031.85 toks/s, output: 757.23 toks/s]\n",
      "Processed prompts: 100%|██████████| 75/75 [00:05<00:00, 14.22it/s, est. speed input: 1031.26 toks/s, output: 756.80 toks/s]\n",
      "Processed prompts: 100%|██████████| 75/75 [00:05<00:00, 13.07it/s, est. speed input: 947.54 toks/s, output: 695.36 toks/s]\n",
      "[2025-07-01 15:35:23,470] - Iteration 1\n",
      "                Elitist (0.959971535314001):\n",
      "                Classify the sentiment of the given text into one of the following categories: positive, negative, or neutral.\n",
      "[2025-07-01 15:35:23,471] - Iteration 1 finished...\n",
      "[2025-07-01 15:35:23,472] - Best score: 0.959971535314001\n",
      "Processed prompts: 100%|██████████| 4/4 [00:00<00:00,  5.36it/s, est. speed input: 1045.47 toks/s, output: 106.02 toks/s]\n",
      "Processed prompts: 100%|██████████| 4/4 [00:01<00:00,  2.98it/s, est. speed input: 473.43 toks/s, output: 114.63 toks/s]\n",
      "[2025-07-01 15:35:25,580] - Evaluating population...\n",
      "Processed prompts: 100%|██████████| 75/75 [00:04<00:00, 15.92it/s, est. speed input: 1042.39 toks/s, output: 717.48 toks/s]\n",
      "Processed prompts: 100%|██████████| 75/75 [00:03<00:00, 19.79it/s, est. speed input: 1296.52 toks/s, output: 437.62 toks/s]\n",
      "Processed prompts: 100%|██████████| 75/75 [00:07<00:00, 10.07it/s, est. speed input: 851.27 toks/s, output: 683.22 toks/s]\n",
      "Processed prompts: 100%|██████████| 75/75 [00:07<00:00, 10.07it/s, est. speed input: 850.77 toks/s, output: 682.81 toks/s]\n",
      "[2025-07-01 15:35:49,233] - Iteration 2\n",
      "                Elitist (0.9732905982905983):\n",
      "                Classify the sentiment of the given text as positive, negative, or neutral. Provide a justification for your classification.\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.69it/s, est. speed input: 307.36 toks/s, output: 37.15 toks/s]\n",
      "Processed prompts: 100%|██████████| 4/4 [00:01<00:00,  2.58it/s, est. speed input: 299.26 toks/s, output: 147.05 toks/s]\n",
      "[2025-07-01 15:35:51,390] - Evaluating population...\n",
      "Processed prompts: 100%|██████████| 75/75 [00:05<00:00, 12.60it/s, est. speed input: 825.68 toks/s, output: 832.23 toks/s]\n",
      "Processed prompts: 100%|██████████| 75/75 [00:05<00:00, 12.55it/s, est. speed input: 822.14 toks/s, output: 828.66 toks/s]\n",
      "Processed prompts: 100%|██████████| 75/75 [00:05<00:00, 12.57it/s, est. speed input: 823.23 toks/s, output: 829.76 toks/s]\n",
      "Processed prompts: 100%|██████████| 75/75 [00:05<00:00, 12.59it/s, est. speed input: 824.49 toks/s, output: 831.03 toks/s]\n",
      "[2025-07-01 15:36:15,489] - Iteration 2\n",
      "                Elitist (0.9732905982905983):\n",
      "                Classify the sentiment of the given text as positive, negative, or neutral. Provide a justification for your classification.\n",
      "[2025-07-01 15:36:15,490] - Iteration 2 finished...\n",
      "[2025-07-01 15:36:15,491] - Best score: 0.9732905982905983\n",
      "[2025-07-01 15:36:15,492] - BEST SCORE: 0.9732905982905983\n",
      "[2025-07-01 15:36:15,493] - BEST PROMPT:\n",
      "Classify the sentiment of the given text as positive, negative, or neutral. Provide a justification for your classification.\n",
      "[2025-07-01 15:36:15,493] - Evaluating population...\n",
      "Processed prompts: 100%|██████████| 25/25 [00:03<00:00,  8.08it/s, est. speed input: 495.89 toks/s, output: 545.96 toks/s]\n",
      "Processed prompts: 100%|██████████| 25/25 [00:03<00:00,  8.07it/s, est. speed input: 495.74 toks/s, output: 545.79 toks/s]\n",
      "Processed prompts: 100%|██████████| 25/25 [00:03<00:00,  8.07it/s, est. speed input: 495.69 toks/s, output: 545.74 toks/s]\n",
      "Processed prompts: 100%|██████████| 25/25 [00:02<00:00,  8.55it/s, est. speed input: 525.33 toks/s, output: 457.56 toks/s]\n",
      "Processed prompts: 100%|██████████| 100/100 [04:49<00:00,  2.90s/it, est. speed input: 16.39 toks/s, output: 733.15 toks/s]\n",
      "Processed prompts: 100%|██████████| 100/100 [00:05<00:00, 16.68it/s, est. speed input: 1075.42 toks/s, output: 854.89 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final prompt: Classify the sentiment of the given text as positive, negative, or neutral. Provide a justification for your classification.\n",
      "Start prompt metric:  0.3254835996635828\n",
      "Final prompt metric:  0.9097744360902256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tuner.run(\n",
    "    start_prompt=\"Perform Sentiment Classification task.\",\n",
    "    task='classification',\n",
    "    dataset=class_dataset,\n",
    "    target=class_targets,\n",
    "    method='reflective',\n",
    "    problem_description='sentiment classification',\n",
    "    use_cache=False,\n",
    "    population_size=4,\n",
    "    num_epochs=3\n",
    ")\n",
    "\n",
    "print_results(tuner)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d8d567",
   "metadata": {},
   "source": [
    "## Evaluator\n",
    "\n",
    "Если вы укажете датасет для оптимизации, фреймворк позволяет измерять метрики, получаемые при использовании определенного промпта\n",
    "\n",
    "На данный момент поддерживаются\n",
    "- accuracy и f1 для классификации\n",
    "- meteor, rouge и bleu для генерации\n",
    "\n",
    "Метрики находятся в публичных полях ассистента"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8a450a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Start prompt metric: \", tuner.init_metric)\n",
    "print(\"Final prompt metric: \", tuner.final_metric)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
