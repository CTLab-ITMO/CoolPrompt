{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d87c389-d114-4b18-a500-8bfd9ec22535",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"../../\"))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from coolprompt.assistant import PromptTuner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a12ce0-63ac-48d3-8b6c-307862598f75",
   "metadata": {},
   "source": [
    "# Basic tutorial of CoolPrompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a0929c-beb9-48be-9d39-387801bcf0df",
   "metadata": {},
   "source": [
    "## Quick Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9089fb7f-a327-4c3f-87a5-0cccc5396586",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-10-01 13:56:15,692] [INFO] [llm.init] - Initializing default model\n",
      "[2025-10-01 13:56:15,694] [DEBUG] [llm.init] - Updating default model params with langchain config: None and vllm_engine_config: None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc33cdd39bfe4fb9a4e72a54006ce99b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "[2025-10-01 13:56:22,130] [INFO] [assistant.__init__] - Validating the target model\n",
      "[2025-10-01 13:56:22,131] [INFO] [assistant.__init__] - PromptTuner successfully initialized\n",
      "[2025-10-01 13:56:22,132] [INFO] [detector.generate] - Detecting the task by query\n",
      "`generation_config` default values have been modified to match model-specific defaults: {'do_sample': True}. If this is not desired, please set these values explicitly.\n",
      "[2025-10-01 13:56:22,783] [INFO] [detector.generate] - Task defined as generation\n",
      "[2025-10-01 13:56:22,784] [INFO] [assistant.run] - Validating args for PromptTuner running\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[2025-10-01 13:56:24,107] [INFO] [evaluator.__init__] - Evaluator successfully initialized with meteor metric\n",
      "[2025-10-01 13:56:24,108] [INFO] [generator.generate] - Problem description was not provided, so it will be generated automatically\n",
      "[2025-10-01 13:56:29,102] [INFO] [generator.generate] - Generated problem description: The user is tasked with composing a well-structured, coherent, and descriptive essay on the theme of autumn. The essay should capture the essential characteristics, sensory experiences, and emotional or cultural significance of the season. It should include natural elements such as falling leaves, changing colors, cooler temperatures, harvest festivals, and seasonal transitions. The essay must be written in clear, engaging prose that conveys a vivid understanding of autumn, demonstrating both observational detail and reflective insight. The goal is to produce a comprehensive and thoughtful piece that educates and inspires the reader about the season's beauty and importance in the natural and human world.\n",
      "[2025-10-01 13:59:01,374] [INFO] [assistant.run] - === Starting Prompt Optimization ===\n",
      "[2025-10-01 13:59:01,375] [INFO] [assistant.run] - Method: hype, Task: generation\n",
      "[2025-10-01 13:59:01,376] [INFO] [assistant.run] - Metric: meteor, Validation size: 0.25\n",
      "[2025-10-01 13:59:01,377] [INFO] [assistant.run] - Dataset: 14 samples\n",
      "[2025-10-01 13:59:01,377] [INFO] [assistant.run] - Target: 14 samples\n",
      "[2025-10-01 13:59:01,378] [INFO] [hype.hype_optimizer] - Running HyPE optimization...\n",
      "[2025-10-01 13:59:16,116] [INFO] [hype.hype_optimizer] - HyPE optimization completed\n",
      "[2025-10-01 13:59:16,117] [INFO] [assistant.run] - Running the prompt format checking...\n",
      "[2025-10-01 13:59:17,415] [INFO] [assistant.run] - Evaluating on given dataset for generation task...\n",
      "[2025-10-01 13:59:17,416] [INFO] [evaluator.evaluate] - Evaluating prompt for generation task on 4 samples\n",
      "[2025-10-01 14:02:01,632] [INFO] [evaluator.evaluate] - Evaluating prompt for generation task on 4 samples\n",
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "[2025-10-01 14:06:24,280] [INFO] [assistant.run] - Initial meteor score: 0.3913055035585572, final meteor score: 0.3241252116292675\n",
      "[2025-10-01 14:06:24,281] [INFO] [assistant.run] - === Prompt Optimization Completed ===\n",
      "[2025-10-01 14:06:37,740] [INFO] [assistant.run] - === Assistant's feedback ===\n",
      "[2025-10-01 14:06:37,741] [INFO] [assistant.run] - Ваш исходный промпт был слишком общим и размытым — «напиши эссе о осени» не задавало конкретных требований к содержанию, структуре или стилю. Улучшенная версия добавляет явную роль (эксперт по письму и наблюдению за сезонами), что помогает модели понять, в каком ключе нужно отвечать. Были введены конкретные элементы: описания природных характеристик (цветение листьев, холод, шум листьев), культурные аспекты (пасха, хэллоуин, урожай), эмоциональная окраска (меланхолия, ностальгия). Структура теперь четко определена: от визуального начала до философского заключения, что обеспечивает логическую и художественную целостность. Также указаны требования к стилю — использовать ощущения, избегать общих фраз, писать в живом, доступном языке. Это делает результат не просто описанием, а глубоким, погружающим текстом. Ключевой совет: всегда уточняйте роль, детали содержания, структуру и стиль в промпте — это превращает общий запрос в точный, эффективный инструктаж для ИИ.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nYou are an expert writer and seasonal observer tasked with composing a rich, well-structured, and vividly descriptive essay on the theme of autumn. Your goal is to create a coherent, engaging, and insightful piece that captures the essence of the season through sensory detail, natural observation, and cultural reflection.\\n\\nBegin by describing the key physical and environmental characteristics of autumn: the transformation of foliage, the gradual cooling of temperatures, the crispness of the air, and the quiet rhythm of nature as leaves fall. Use specific, evocative language to convey sight, sound, smell, and touch—such as the rustle of dry leaves, the golden light filtering through trees, or the earthy scent of damp soil after rain.\\n\\nIntegrate cultural and human elements of autumn, including harvest festivals (e.g., Thanksgiving, Halloween, harvest fairs), traditional foods (e.g., apples, pumpkins, squash), and seasonal rituals that reflect humanity’s connection to nature. Reflect on the emotional tone of autumn—its melancholy, nostalgia, abundance, and transition—offering thoughtful insights into how people perceive and respond to the season’s changes.\\n\\nStructure your essay with a clear narrative arc: open with a vivid scene or sensory moment, develop through observations and reflections, and conclude with a broader philosophical or emotional takeaway about the value of seasonal change, impermanence, and balance in life.\\n\\nWrite in clear, natural prose that is accessible and immersive. Avoid generic statements; instead, ground your writing in specific details and personal or universal reflections. Ensure the essay is comprehensive, thoughtful, and inspiring—offering readers not just a description of autumn, but a deeper appreciation for its beauty and significance in both the natural world and human experience.\\n\\nMaintain a consistent tone that is reflective yet lively, poetic yet grounded. Do not include any code, technical jargon, or irrelevant content.\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from coolprompt.assistant import PromptTuner\n",
    "\n",
    "tuner = PromptTuner()\n",
    "\n",
    "tuner.run('Write an essay about autumn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93d489c9-65a1-47d1-bb71-d6a03bf614ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are an expert writer and seasonal observer tasked with composing a rich, well-structured, and vividly descriptive essay on the theme of autumn. Your goal is to create a coherent, engaging, and insightful piece that captures the essence of the season through sensory detail, natural observation, and cultural reflection.\n",
      "\n",
      "Begin by describing the key physical and environmental characteristics of autumn: the transformation of foliage, the gradual cooling of temperatures, the crispness of the air, and the quiet rhythm of nature as leaves fall. Use specific, evocative language to convey sight, sound, smell, and touch—such as the rustle of dry leaves, the golden light filtering through trees, or the earthy scent of damp soil after rain.\n",
      "\n",
      "Integrate cultural and human elements of autumn, including harvest festivals (e.g., Thanksgiving, Halloween, harvest fairs), traditional foods (e.g., apples, pumpkins, squash), and seasonal rituals that reflect humanity’s connection to nature. Reflect on the emotional tone of autumn—its melancholy, nostalgia, abundance, and transition—offering thoughtful insights into how people perceive and respond to the season’s changes.\n",
      "\n",
      "Structure your essay with a clear narrative arc: open with a vivid scene or sensory moment, develop through observations and reflections, and conclude with a broader philosophical or emotional takeaway about the value of seasonal change, impermanence, and balance in life.\n",
      "\n",
      "Write in clear, natural prose that is accessible and immersive. Avoid generic statements; instead, ground your writing in specific details and personal or universal reflections. Ensure the essay is comprehensive, thoughtful, and inspiring—offering readers not just a description of autumn, but a deeper appreciation for its beauty and significance in both the natural world and human experience.\n",
      "\n",
      "Maintain a consistent tone that is reflective yet lively, poetic yet grounded. Do not include any code, technical jargon, or irrelevant content.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tuner.final_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5854dd0b-0e49-46f9-b881-367e446afa05",
   "metadata": {},
   "source": [
    "### What happened step-by-step\n",
    "1. We initialized a CoolPrompt Tuner with default large language model: qwen3-4B-instruct\n",
    "2. We input a start prompt that should be modified\n",
    "3. CoolPrompt auto-detected preferred task and metric for prompt optimization and evaluation\n",
    "4. CoolPrompt PromptAssistant generated automatically the dataset with target labels and split into train and test samples\n",
    "5. The default prompt optimizer HyPE suggested the optimized prompt\n",
    "6. CoolPrompt outputs the results:\n",
    "   - Metric scores of optimization efficiency\n",
    "   - The final prompt\n",
    "   - The interpretation of prompt optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42992843-51c8-4d39-9b3b-98935d6764e8",
   "metadata": {},
   "source": [
    "### That is a simple approach how to optimize prompts. Let's try to configure CoolPrompt Tuner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fe16ef-f038-44f8-a080-a07816042060",
   "metadata": {},
   "source": [
    "## Setup a CoolPrompt Tuner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ec42bb-400c-4705-922c-661e67761f36",
   "metadata": {},
   "source": [
    "### 1. LLM Choice\n",
    "The framework is a model-agnostic, you can use proprietary, open-source or custom LLMs with different interfaces via LangChain compatibility. \n",
    "\n",
    "#### Check [the full list of provider interfaces](https://python.langchain.com/docs/integrations/llms/).\n",
    "\n",
    "Default LLM in CoolPrompt is Qwen/Qwen3-4B-Instruct-2507 and it a same can be defined as:\n",
    "```python\n",
    "llm = HuggingFacePipeline.from_model_id(\n",
    "    model_id=\"Qwen/Qwen3-4B-Instruct-2507\",\n",
    "    task=\"text-generation\",\n",
    "    pipeline_kwargs={\n",
    "        \"max_new_tokens\": 4000,\n",
    "        \"temperature\": 0.01,\n",
    "        \"do_sample\": False,\n",
    "        \"return_full_text\": False,\n",
    "    }\n",
    ")\n",
    "target_model = ChatHuggingFace(llm=llm)\n",
    "\n",
    "tuner = PromptTuner(target_model=target_model)\n",
    "```\n",
    "\n",
    "You can use other popular interfaces as:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed22194f-1ae6-4ebd-8df5-5adc9419fb8d",
   "metadata": {},
   "source": [
    "#### Ollama\n",
    "For rapid experiments with low resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5481eb-d2f8-46fb-97e9-a857443f5fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama.llms import OllamaLLM\n",
    "\n",
    "my_model = OllamaLLM(\n",
    "    model=\"qwen2.5-coder:32b\"\n",
    ")\n",
    "prompt_tuner = PromptTuner(target_model=my_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288eb4dc-5335-4d36-a36d-c5353ad59093",
   "metadata": {},
   "source": [
    "#### VLLM\n",
    "As a production ready solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c87892-bdfc-472c-82b3-d850036187d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import VLLM\n",
    "\n",
    "my_model = VLLM(\n",
    "    model=\"Qwen/Qwen3-4B-Instruct-2507\",\n",
    "    trust_remote_code=True,\n",
    "    dtype='bfloat16',\n",
    ")\n",
    "\n",
    "prompt_tuner = PromptTuner(target_model=my_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad91b7b6-227f-43b6-b390-16954fc0b729",
   "metadata": {},
   "source": [
    "#### ChatOpenAI\n",
    "For OpenAI and OpenAI compatible models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da88cbcf-e003-4f0c-ac15-6f52fb5e8af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "my_model = ChatOpenAI(\n",
    "    model=\"paste model_name\",\n",
    "    base_url=\"paste base_url\",\n",
    "    openai_api_key=\"paste api_key\",\n",
    "    temperature=0.01,\n",
    "    max_tokens=4000,\n",
    ")\n",
    "\n",
    "prompt_tuner = PromptTuner(target_model=my_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1419b38-296b-4a62-b943-5034bb5c22e6",
   "metadata": {},
   "source": [
    "### 2. System Model\n",
    "Argument `system_model` defines a core in a **PromptAssistant** module.\n",
    "\n",
    "**PromptAssistant** is responsible for:\n",
    "- Definition automatically a task type and a metric for the specific start prompt.\n",
    "- Generates a syntetic dataset and target labels (when the real data is not provided).\n",
    "- Provides an Assistant Feedback or Optimization Interpretation.\n",
    "\n",
    "By default a `system_model` is a defined the same as a `target_model`. It could be set with a different llm in code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f20e3e-45a6-4943-896b-52ca891bcc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import VLLM\n",
    "\n",
    "target_model = VLLM(\n",
    "    model=\"Qwen/Qwen3-4B-Instruct-2507\"\n",
    ")\n",
    "system_model = VLLM(\n",
    "    model=\"Qwen/Qwen3-30B-A3B-Instruct-2507\"\n",
    ")\n",
    "\n",
    "prompt_tuner = PromptTuner(\n",
    "    target_model=target_model,\n",
    "    system_model=system_model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e308fa-c9fd-46b3-bfd2-8d2db922a86b",
   "metadata": {},
   "source": [
    "#### IMPORTANT NOTE: `system_model` needs to be a confident instructional llm that can generate a structual output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8445763b-db76-445f-99b5-48c7fe558455",
   "metadata": {},
   "source": [
    "### 3. Task and metrics\n",
    "CoolPrompt supports 2 task types and a set of metrics: \n",
    "- `classification` - a common classification\n",
    "    - `accuracy`\n",
    "    - `f1` (f1-macro)\n",
    "- `generation` - a general new text generation\n",
    "    - `bleu`\n",
    "    - `rouge`\n",
    "    - `meteor`\n",
    "    - `bertscore`\n",
    "    - `geval` (one metric: *textual accuracy*)\n",
    "\n",
    "For each run you can define as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3efad17-c57a-4fd9-b5c4-bb8911b47898",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_tuner.run(\n",
    "    start_prompt=\"Classify a sentence sentiment\",\n",
    "    task=\"classification\",\n",
    "    metric=\"f1\",\n",
    ")\n",
    "\n",
    "prompt_tuner.run(\n",
    "    start_prompt=\"Summarize the text\",\n",
    "    task=\"generation\",\n",
    "    metric=\"rouge\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7c49d5-5dcb-4c3e-93ec-228672efea11",
   "metadata": {},
   "source": [
    "### 4. Providing a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df954db-0077-499a-a6c4-4e937aa26de1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0605029-4dbb-450a-a313-3e0abd342be7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623382a1-f3e7-4b2f-90aa-e5f15c44b7c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed121ec-45cb-4645-b3d5-df859db9f9dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
