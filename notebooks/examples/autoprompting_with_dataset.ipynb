{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3f56aae-ee54-4085-a36e-4240b7a90931",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"../../\"))\n",
    "sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f86dd4df-d2fd-4c63-bc0b-27f1a1f46ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "sst2 = load_dataset(\"stanfordnlp/sst2\")\n",
    "class_dataset = sst2['train']['sentence'][:100]\n",
    "class_targets = sst2['train']['label'][:100]\n",
    "\n",
    "samsum = load_dataset(\"knkarthick/samsum\")\n",
    "gen_dataset = samsum['train']['dialogue'][:100]\n",
    "gen_targets = samsum['train']['summary'][:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa85cc60",
   "metadata": {},
   "source": [
    "Starting with PromptTuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56671cb8-25c0-4eee-b469-c3cf45c6e2e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-07-09 00:56:30,551] [INFO] [llm.init] - Initializing default model\n",
      "[2025-07-09 00:56:30,551] [DEBUG] [llm.init] - Updating default model params with langchain config: None and vllm_engine_config: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 07-09 00:56:32 __init__.py:207] Automatically detected platform cuda.\n",
      "WARNING 07-09 00:56:32 config.py:2448] Casting torch.bfloat16 to torch.float16.\n",
      "INFO 07-09 00:56:40 config.py:549] This model supports multiple tasks: {'classify', 'reward', 'generate', 'embed', 'score'}. Defaulting to 'generate'.\n",
      "INFO 07-09 00:56:40 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='t-tech/T-lite-it-1.0', speculative_config=None, tokenizer='t-tech/T-lite-it-1.0', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=32768, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=t-tech/T-lite-it-1.0, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"splitting_ops\":[],\"compile_sizes\":[],\"cudagraph_capture_sizes\":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":256}, use_cached_outputs=False, \n",
      "INFO 07-09 00:56:42 cuda.py:178] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\n",
      "INFO 07-09 00:56:42 cuda.py:226] Using XFormers backend.\n",
      "INFO 07-09 00:56:43 model_runner.py:1110] Starting to load model t-tech/T-lite-it-1.0...\n",
      "INFO 07-09 00:56:43 weight_utils.py:254] Using model weights format ['*.safetensors']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dc6b5ec3f6d44c4b0adeaa1f21fcb63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 07-09 00:58:48 model_runner.py:1115] Loading model weights took 14.2426 GB\n",
      "INFO 07-09 00:58:53 worker.py:267] Memory profiling takes 5.28 seconds\n",
      "INFO 07-09 00:58:53 worker.py:267] the current vLLM instance can use total_gpu_memory (23.64GiB) x gpu_memory_utilization (0.90) = 21.27GiB\n",
      "INFO 07-09 00:58:53 worker.py:267] model weights take 14.24GiB; non_torch_memory takes 0.06GiB; PyTorch activation peak memory takes 4.35GiB; the rest of the memory reserved for KV Cache is 2.62GiB.\n",
      "INFO 07-09 00:58:54 executor_base.py:111] # cuda blocks: 3069, # CPU blocks: 4681\n",
      "INFO 07-09 00:58:54 executor_base.py:116] Maximum concurrency for 32768 tokens per request: 1.50x\n",
      "INFO 07-09 00:59:01 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Capturing CUDA graph shapes: 100%|██████████████████████████| 35/35 [00:16<00:00,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 07-09 00:59:18 model_runner.py:1562] Graph capturing finished in 17 secs, took 0.21 GiB\n",
      "INFO 07-09 00:59:18 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 30.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[2025-07-09 00:59:18,449] [INFO] [assistant.__init__] - Validating the model: VLLM\n",
      "[2025-07-09 00:59:18,451] [INFO] [assistant.__init__] - PromptTuner successfully initialized with model: VLLM\n",
      "[2025-07-09 00:59:18,452] [INFO] [assistant.run] - Validating args for PromptTuner running\n",
      "[2025-07-09 00:59:19,205] [INFO] [evaluator.__init__] - Evaluator sucessfully initialized with f1 metric\n",
      "[2025-07-09 00:59:19,206] [INFO] [assistant.run] - === Starting Prompt Optimization ===\n",
      "[2025-07-09 00:59:19,206] [INFO] [assistant.run] - Method: hype, Task: classification\n",
      "[2025-07-09 00:59:19,207] [INFO] [assistant.run] - Metric: f1, Validation size: 0.25\n",
      "[2025-07-09 00:59:19,208] [INFO] [assistant.run] - Dataset: 100 samples\n",
      "[2025-07-09 00:59:19,208] [INFO] [assistant.run] - Target: 100 samples\n",
      "[2025-07-09 00:59:19,209] [INFO] [hype.hype_optimizer] - Running HyPE optimization...\n",
      "Processed prompts: 100%|█| 1/1 [00:00<00:00,  1.32it/s, est. speed input: 328.07 toks/s, out\n",
      "[2025-07-09 00:59:19,993] [INFO] [hype.hype_optimizer] - HyPE optimization completed\n",
      "[2025-07-09 00:59:19,993] [INFO] [assistant.run] - Evaluating on given dataset for classification task...\n",
      "[2025-07-09 00:59:19,994] [INFO] [evaluator.evaluate] - Evaluating prompt for classification task on 100 samples\n",
      "Processed prompts: 100%|█| 100/100 [01:48<00:00,  1.08s/it, est. speed input: 276.26 toks/s,\n",
      "[2025-07-09 01:01:08,489] [INFO] [evaluator.evaluate] - Evaluating prompt for classification task on 100 samples\n",
      "Processed prompts: 100%|█| 100/100 [00:05<00:00, 16.94it/s, est. speed input: 5260.67 toks/s\n",
      "[2025-07-09 01:01:14,480] [INFO] [assistant.run] - Initial f1 score: 0.6364983164983165, final f1 score: 0.8899889988998899\n",
      "[2025-07-09 01:01:14,481] [INFO] [assistant.run] - === Prompt Optimization Completed ===\n"
     ]
    }
   ],
   "source": [
    "from coolprompt.assistant import PromptTuner\n",
    "\n",
    "# Define an initial prompt\n",
    "class_start_prompt = \"Classify sentence sentiment\"\n",
    "\n",
    "# Initialize the tuner\n",
    "tuner = PromptTuner()\n",
    "\n",
    "# Call prompt optimization with dataset and target\n",
    "final_prompt = tuner.run(\n",
    "    start_prompt=class_start_prompt,\n",
    "    task=\"classification\",\n",
    "    dataset=class_dataset,\n",
    "    target=class_targets,\n",
    "    metric=\"f1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dc088b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final prompt: Please provide a sentence and classify its sentiment as positive, negative, or neutral.\n",
      "Start prompt metric:  0.6364983164983165\n",
      "Final prompt metric:  0.8899889988998899\n"
     ]
    }
   ],
   "source": [
    "print(\"Final prompt:\", final_prompt)\n",
    "print(\"Start prompt metric: \", tuner.init_metric)\n",
    "print(\"Final prompt metric: \", tuner.final_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df89a78",
   "metadata": {},
   "source": [
    "You can do the same with generation task\n",
    "\n",
    "Also you can reuse previous tuner binded to LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06adb513",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-07-09 01:04:23,098] [INFO] [llm.init] - Initializing default model\n",
      "[2025-07-09 01:04:23,099] [DEBUG] [llm.init] - Updating default model params with langchain config: None and vllm_engine_config: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 07-09 01:04:24 __init__.py:207] Automatically detected platform cuda.\n",
      "WARNING 07-09 01:04:25 config.py:2448] Casting torch.bfloat16 to torch.float16.\n",
      "INFO 07-09 01:04:33 config.py:549] This model supports multiple tasks: {'classify', 'embed', 'score', 'generate', 'reward'}. Defaulting to 'generate'.\n",
      "INFO 07-09 01:04:33 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='t-tech/T-lite-it-1.0', speculative_config=None, tokenizer='t-tech/T-lite-it-1.0', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=32768, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=t-tech/T-lite-it-1.0, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"splitting_ops\":[],\"compile_sizes\":[],\"cudagraph_capture_sizes\":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":256}, use_cached_outputs=False, \n",
      "INFO 07-09 01:04:35 cuda.py:178] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\n",
      "INFO 07-09 01:04:35 cuda.py:226] Using XFormers backend.\n",
      "INFO 07-09 01:04:36 model_runner.py:1110] Starting to load model t-tech/T-lite-it-1.0...\n",
      "INFO 07-09 01:04:36 weight_utils.py:254] Using model weights format ['*.safetensors']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1380c1568b64b1784ea83d300356e7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 07-09 01:06:41 model_runner.py:1115] Loading model weights took 14.2426 GB\n",
      "INFO 07-09 01:06:46 worker.py:267] Memory profiling takes 5.32 seconds\n",
      "INFO 07-09 01:06:46 worker.py:267] the current vLLM instance can use total_gpu_memory (23.64GiB) x gpu_memory_utilization (0.90) = 21.27GiB\n",
      "INFO 07-09 01:06:46 worker.py:267] model weights take 14.24GiB; non_torch_memory takes 0.06GiB; PyTorch activation peak memory takes 4.35GiB; the rest of the memory reserved for KV Cache is 2.62GiB.\n",
      "INFO 07-09 01:06:47 executor_base.py:111] # cuda blocks: 3069, # CPU blocks: 4681\n",
      "INFO 07-09 01:06:47 executor_base.py:116] Maximum concurrency for 32768 tokens per request: 1.50x\n",
      "INFO 07-09 01:06:54 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Capturing CUDA graph shapes: 100%|██████████████████████████| 35/35 [00:16<00:00,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 07-09 01:07:11 model_runner.py:1562] Graph capturing finished in 17 secs, took 0.21 GiB\n",
      "INFO 07-09 01:07:11 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 30.44 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[2025-07-09 01:07:11,872] [INFO] [assistant.__init__] - Validating the model: VLLM\n",
      "[2025-07-09 01:07:11,873] [INFO] [assistant.__init__] - PromptTuner successfully initialized with model: VLLM\n"
     ]
    }
   ],
   "source": [
    "from coolprompt.assistant import PromptTuner\n",
    "\n",
    "# Define an initial prompt\n",
    "class_start_prompt = \"Classify sentence sentiment\"\n",
    "\n",
    "# Initialize the tuner\n",
    "tuner = PromptTuner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3132db14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-07-09 01:09:57,414] [INFO] [assistant.run] - Validating args for PromptTuner running\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /nfs/home/asitkina/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /nfs/home/asitkina/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /nfs/home/asitkina/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[2025-07-09 01:09:59,450] [INFO] [evaluator.__init__] - Evaluator sucessfully initialized with meteor metric\n",
      "[2025-07-09 01:09:59,450] [INFO] [assistant.run] - === Starting Prompt Optimization ===\n",
      "[2025-07-09 01:09:59,451] [INFO] [assistant.run] - Method: hype, Task: generation\n",
      "[2025-07-09 01:09:59,451] [INFO] [assistant.run] - Metric: meteor, Validation size: 0.25\n",
      "[2025-07-09 01:09:59,452] [INFO] [assistant.run] - Dataset: 100 samples\n",
      "[2025-07-09 01:09:59,453] [INFO] [assistant.run] - Target: 100 samples\n",
      "[2025-07-09 01:09:59,453] [INFO] [hype.hype_optimizer] - Running HyPE optimization...\n",
      "Processed prompts: 100%|█| 1/1 [00:00<00:00,  1.10it/s, est. speed input: 275.80 toks/s, out\n",
      "[2025-07-09 01:10:00,386] [INFO] [hype.hype_optimizer] - HyPE optimization completed\n",
      "[2025-07-09 01:10:00,387] [INFO] [assistant.run] - Evaluating on given dataset for generation task...\n",
      "[2025-07-09 01:10:00,387] [INFO] [evaluator.evaluate] - Evaluating prompt for generation task on 100 samples\n",
      "Processed prompts: 100%|█| 100/100 [00:10<00:00,  9.87it/s, est. speed input: 3863.51 toks/s\n",
      "[2025-07-09 01:10:13,235] [INFO] [evaluator.evaluate] - Evaluating prompt for generation task on 100 samples\n",
      "Processed prompts: 100%|█| 100/100 [00:11<00:00,  9.00it/s, est. speed input: 3658.18 toks/s\n",
      "[2025-07-09 01:10:24,551] [INFO] [assistant.run] - Initial meteor score: 0.2889385547946554, final meteor score: 0.30479966549868787\n",
      "[2025-07-09 01:10:24,551] [INFO] [assistant.run] - === Prompt Optimization Completed ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final prompt: Please provide a concise summary of the text, focusing on the main points and omitting any unnecessary details.\n",
      "Start prompt metric:  0.2889385547946554\n",
      "Final prompt metric:  0.30479966549868787\n"
     ]
    }
   ],
   "source": [
    "gen_start_prompt = \"Summarize this text\"\n",
    "\n",
    "final_prompt = tuner.run(\n",
    "    start_prompt=gen_start_prompt,\n",
    "    task=\"generation\",\n",
    "    dataset=gen_dataset,\n",
    "    target=gen_targets,\n",
    "    metric=\"meteor\"\n",
    ")\n",
    "\n",
    "print(\"Final prompt:\", final_prompt)\n",
    "print(\"Start prompt metric: \", tuner.init_metric)\n",
    "print(\"Final prompt metric: \", tuner.final_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ea40cb",
   "metadata": {},
   "source": [
    "Currently supported metrics are\n",
    "- accuracy and f1 for classification\n",
    "- meteor, bleu and rouge for generation\n",
    "\n",
    "Also, task type must correspond the metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86c9016a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-07-09 01:10:35,570] [INFO] [assistant.run] - Validating args for PromptTuner running\n",
      "[2025-07-09 01:10:35,571] [ERROR] [metrics.validate_and_create_metric] - Invalid metric for classification task: rouge. Available metrics: accuracy, f1.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid metric for classification task: rouge. Available metrics: accuracy, f1.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtuner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstart_prompt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclass_start_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mclassification\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclass_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclass_targets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrouge\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m      7\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/tank/scratch/asitkina/CoolPrompt/coolprompt/assistant.py:167\u001b[39m, in \u001b[36mPromptTuner.run\u001b[39m\u001b[34m(self, start_prompt, task, dataset, target, method, metric, problem_description, validation_size, verbose, **kwargs)\u001b[39m\n\u001b[32m    157\u001b[39m logger.info(\u001b[33m\"\u001b[39m\u001b[33mValidating args for PromptTuner running\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    158\u001b[39m task, method = validate_run(\n\u001b[32m    159\u001b[39m     start_prompt,\n\u001b[32m    160\u001b[39m     task,\n\u001b[32m   (...)\u001b[39m\u001b[32m    165\u001b[39m     validation_size,\n\u001b[32m    166\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m metric = \u001b[43mvalidate_and_create_metric\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    168\u001b[39m evaluator = Evaluator(\u001b[38;5;28mself\u001b[39m._model, task, metric)\n\u001b[32m    169\u001b[39m final_prompt = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/tank/scratch/asitkina/CoolPrompt/coolprompt/evaluator/metrics.py:229\u001b[39m, in \u001b[36mvalidate_and_create_metric\u001b[39m\u001b[34m(task, metric)\u001b[39m\n\u001b[32m    224\u001b[39m     error_msg = (\n\u001b[32m    225\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid metric for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtask\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m task: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAvailable metrics: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(CLASSIFICATION_METRICS)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    227\u001b[39m     )\n\u001b[32m    228\u001b[39m     logger.error(error_msg)\n\u001b[32m--> \u001b[39m\u001b[32m229\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(error_msg)\n\u001b[32m    230\u001b[39m \u001b[38;5;28;01mcase\u001b[39;00m Task.GENERATION:\n\u001b[32m    231\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m metric \u001b[38;5;129;01min\u001b[39;00m GENERATION_METRICS:\n",
      "\u001b[31mValueError\u001b[39m: Invalid metric for classification task: rouge. Available metrics: accuracy, f1."
     ]
    }
   ],
   "source": [
    "tuner.run(\n",
    "    start_prompt=class_start_prompt,\n",
    "    task=\"classification\",\n",
    "    dataset=class_dataset,\n",
    "    target=class_targets,\n",
    "    metric=\"rouge\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd599b2d",
   "metadata": {},
   "source": [
    "There are two ways to initialize tuner with your custom LLM\n",
    "\n",
    "To init a model by yourself and pass it to the tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3bc6647",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_community\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mllms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VLLM\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m my_model = \u001b[43mVLLM\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdeepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfloat16\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m tuner_with_custom_llm = PromptTuner(model=my_model)\n\u001b[32m     10\u001b[39m tuner_with_custom_llm.run(start_prompt=\u001b[33m\"\u001b[39m\u001b[33mWrite an essay about autumn\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/langchain_core/load/serializable.py:130\u001b[39m, in \u001b[36mSerializable.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    129\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: D419\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[31m[... skipping hidden 1 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/pydantic/_internal/_decorators_v1.py:148\u001b[39m, in \u001b[36mmake_v1_generic_root_validator.<locals>._wrapper1\u001b[39m\u001b[34m(values, _)\u001b[39m\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_wrapper1\u001b[39m(values: RootValidatorValues, _: core_schema.ValidationInfo) -> RootValidatorValues:\n\u001b[32m--> \u001b[39m\u001b[32m148\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvalidator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/langchain_core/utils/pydantic.py:226\u001b[39m, in \u001b[36mpre_init.<locals>.wrapper\u001b[39m\u001b[34m(cls, values)\u001b[39m\n\u001b[32m    223\u001b[39m             values[name] = field_info.default\n\u001b[32m    225\u001b[39m \u001b[38;5;66;03m# Call the decorated function\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m226\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/langchain_community/llms/vllm.py:82\u001b[39m, in \u001b[36mVLLM.validate_environment\u001b[39m\u001b[34m(cls, values)\u001b[39m\n\u001b[32m     79\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Validate that python package exists in environment.\"\"\"\u001b[39;00m\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LLM \u001b[38;5;28;01mas\u001b[39;00m VLLModel\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m     84\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m     85\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCould not import vllm python package. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     86\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease install it with `pip install vllm`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     87\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/vllm/__init__.py:11\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mengine\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01marg_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AsyncEngineArgs, EngineArgs\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mengine\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01masync_llm_engine\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AsyncLLMEngine\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mengine\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mllm_engine\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LLMEngine\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/vllm/engine/arg_utils.py:13\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01menvs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01menvs\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (CacheConfig, CompilationConfig, ConfigFormat,\n\u001b[32m     14\u001b[39m                          DecodingConfig, DeviceConfig, HfOverrides,\n\u001b[32m     15\u001b[39m                          KVTransferConfig, LoadConfig, LoadFormat, LoRAConfig,\n\u001b[32m     16\u001b[39m                          ModelConfig, ModelImpl, ObservabilityConfig,\n\u001b[32m     17\u001b[39m                          ParallelConfig, PoolerConfig, PromptAdapterConfig,\n\u001b[32m     18\u001b[39m                          SchedulerConfig, SpeculativeConfig, TaskOption,\n\u001b[32m     19\u001b[39m                          TokenizerPoolConfig, VllmConfig)\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexecutor\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexecutor_base\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ExecutorBase\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlogger\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m init_logger\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/vllm/config.py:24\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompilation\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01minductor_pass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CallableInductorPass, InductorPass\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlogger\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m init_logger\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_executor\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mquantization\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (QUANTIZATION_METHODS,\n\u001b[32m     25\u001b[39m                                                      get_quantization_config)\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_executor\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ModelRegistry\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mplatforms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CpuArchEnum\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/vllm/model_executor/__init__.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# SPDX-License-Identifier: Apache-2.0\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_executor\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mparameter\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (BasevLLMParameter,\n\u001b[32m      4\u001b[39m                                            PackedvLLMParameter)\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_executor\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msampling_metadata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (SamplingMetadata,\n\u001b[32m      6\u001b[39m                                                    SamplingMetadataCache)\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_executor\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m set_random_seed\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/vllm/model_executor/parameter.py:9\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Parameter\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistributed\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_tensor_model_parallel_rank\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlogger\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m init_logger\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_executor\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _make_synced_weight_loader\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/vllm/distributed/__init__.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# SPDX-License-Identifier: Apache-2.0\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcommunication_op\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mparallel_state\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/vllm/distributed/communication_op.py:8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistributed\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mparallel_state\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_tp_group\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtensor_model_parallel_all_reduce\u001b[39m(input_: torch.Tensor) -> torch.Tensor:\n\u001b[32m     12\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"All-reduce the input tensor across model parallel group.\"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/vllm/distributed/parallel_state.py:40\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistributed\u001b[39;00m\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistributed\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Backend, ProcessGroup\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistributed\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkv_transfer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkv_transfer_agent\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkv_transfer\u001b[39;00m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01menvs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01menvs\u001b[39;00m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistributed\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdevice_communicators\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase_device_communicator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     43\u001b[39m     DeviceCommunicatorBase)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/vllm/distributed/kv_transfer/kv_transfer_agent.py:16\u001b[39m\n\u001b[32m     12\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VllmConfig\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistributed\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkv_transfer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkv_connector\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfactory\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     17\u001b[39m     KVConnectorFactory)\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlogger\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m init_logger\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msequence\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m IntermediateTensors\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/vllm/distributed/kv_transfer/kv_connector/factory.py:6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mimportlib\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING, Callable, Dict, Type\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KVConnectorBase\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[32m      9\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VllmConfig\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/vllm/distributed/kv_transfer/kv_connector/base.py:15\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING, List, Tuple, Union\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msequence\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m IntermediateTensors\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[32m     18\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VllmConfig\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/vllm/sequence.py:17\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmsgspec\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01minputs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SingletonInputs, SingletonInputsAdapter\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlora\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrequest\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LoRARequest\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmultimodal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MultiModalDataDict, MultiModalPlaceholderDict\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/vllm/inputs/__init__.py:9\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# SPDX-License-Identifier: Apache-2.0\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (DecoderOnlyInputs, EncoderDecoderInputs,\n\u001b[32m      4\u001b[39m                    ExplicitEncoderDecoderPrompt, ProcessorInputs, PromptType,\n\u001b[32m      5\u001b[39m                    SingletonInputs, SingletonInputsAdapter, SingletonPrompt,\n\u001b[32m      6\u001b[39m                    TextPrompt, TokenInputs, TokensPrompt,\n\u001b[32m      7\u001b[39m                    build_explicit_enc_dec_prompt, to_enc_dec_tuple_list,\n\u001b[32m      8\u001b[39m                    token_inputs, zip_enc_dec_prompts)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mregistry\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (DummyData, InputContext, InputProcessingContext,\n\u001b[32m     10\u001b[39m                        InputRegistry)\n\u001b[32m     12\u001b[39m INPUT_REGISTRY = InputRegistry()\n\u001b[32m     13\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[33;03mThe global :class:`~InputRegistry` which is used by :class:`~vllm.LLMEngine`\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[33;03mto dispatch data processing according to the target model.\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/vllm/inputs/registry.py:10\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (TYPE_CHECKING, Any, Callable, Mapping, NamedTuple,\n\u001b[32m      7\u001b[39m                     Optional, Protocol, Union)\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m nn\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BatchFeature, PretrainedConfig, ProcessorMixin\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping_extensions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TypeVar, assert_never\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlogger\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m init_logger\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1412\u001b[39m, in \u001b[36m_handle_fromlist\u001b[39m\u001b[34m(module, fromlist, import_, recursive)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/transformers/utils/import_utils.py:2045\u001b[39m, in \u001b[36m_LazyModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   2043\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._class_to_module.keys():\n\u001b[32m   2044\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2045\u001b[39m         module = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2046\u001b[39m         value = \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[32m   2047\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/transformers/utils/import_utils.py:2073\u001b[39m, in \u001b[36m_LazyModule._get_module\u001b[39m\u001b[34m(self, module_name)\u001b[39m\n\u001b[32m   2071\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_module\u001b[39m(\u001b[38;5;28mself\u001b[39m, module_name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m   2072\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2073\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[34;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   2074\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   2075\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/importlib/__init__.py:90\u001b[39m, in \u001b[36mimport_module\u001b[39m\u001b[34m(name, package)\u001b[39m\n\u001b[32m     88\u001b[39m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m     89\u001b[39m         level += \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/transformers/processing_utils.py:35\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdynamic_module_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m custom_object_save\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfeature_extraction_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BatchFeature\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimage_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChannelDimension, ImageInput, is_valid_image, is_vision_available, load_image\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchat_template_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m render_jinja_template\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvideo_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VideoInput, load_video\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/transformers/image_utils.py:59\u001b[39m\n\u001b[32m     56\u001b[39m     PILImageResampling = PIL.Image\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_torchvision_available():\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorchvision\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtransforms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m InterpolationMode\n\u001b[32m     61\u001b[39m     pil_torch_interpolation_mapping = {\n\u001b[32m     62\u001b[39m         PILImageResampling.NEAREST: InterpolationMode.NEAREST_EXACT,\n\u001b[32m     63\u001b[39m         PILImageResampling.BOX: InterpolationMode.BOX,\n\u001b[32m   (...)\u001b[39m\u001b[32m     67\u001b[39m         PILImageResampling.LANCZOS: InterpolationMode.LANCZOS,\n\u001b[32m     68\u001b[39m     }\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/torchvision/__init__.py:10\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Don't re-order these, we need to load the _C extension (done when importing\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# .extensions) before entering _meta_registrations.\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mextension\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _HAS_OPS  \u001b[38;5;66;03m# usort:skip\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorchvision\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _meta_registrations, datasets, io, models, ops, transforms, utils  \u001b[38;5;66;03m# usort:skip\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mversion\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/torchvision/models/__init__.py:2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01malexnet\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconvnext\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdensenet\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mefficientnet\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/torchvision/models/convnext.py:8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m nn, Tensor\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m functional \u001b[38;5;28;01mas\u001b[39;00m F\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mops\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmisc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Conv2dNormActivation, Permute\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mops\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstochastic_depth\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StochasticDepth\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtransforms\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_presets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ImageClassification\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/torchvision/ops/__init__.py:23\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgiou_loss\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m generalized_box_iou_loss\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmisc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Conv2dNormActivation, Conv3dNormActivation, FrozenBatchNorm2d, MLP, Permute, SqueezeExcitation\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpoolers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MultiScaleRoIAlign\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mps_roi_align\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ps_roi_align, PSRoIAlign\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mps_roi_pool\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ps_roi_pool, PSRoIPool\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/torchvision/ops/poolers.py:10\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorchvision\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mops\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mboxes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m box_area\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _log_api_usage_once\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mroi_align\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m roi_align\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# copying result_idx_in_level to a specific index in result[]\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# is not supported by ONNX tracing yet.\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# _onnx_merge_levels() is an implementation supported by ONNX\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# that merges the levels to the right indices\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;129m@torch\u001b[39m.jit.unused\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_onnx_merge_levels\u001b[39m(levels: Tensor, unmerged_results: List[Tensor]) -> Tensor:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/torchvision/ops/roi_align.py:7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfx\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m nn, Tensor\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_compile_supported\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mjit\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mannotations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BroadcastingList2\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodules\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _pair\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/torch/_dynamo/__init__.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m convert_frame, eval_frame, resume_execution\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackends\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mregistry\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m list_backends, lookup_backend, register_backend\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcallback\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m callback_handler, on_compile_end, on_compile_start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:31\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_C\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mguards\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GlobalStateGuard\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistributed\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_compile_pg\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CompileTimeInstructionCounter\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_guards\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compile_context, CompileContext, CompileId, tracing\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_logging\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m structured\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/torch/_dynamo/utils.py:62\u001b[39m\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_functorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_inductor\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01minductor_config\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfx\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexperimental\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msymbolic_shapes\u001b[39;00m\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_pytree\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpytree\u001b[39;00m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m fx\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:65\u001b[39m\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_guards\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ShapeGuard, Source, TracingContext\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_python_dispatch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_traceable_wrapper_subclass\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_sympy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunctions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     66\u001b[39m     Application, FloorDiv, Mod, PythonMod, IsNonOverlappingAndDenseIndicator, CleanDiv, FloorToInt, CeilToInt\n\u001b[32m     67\u001b[39m )\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_sympy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msolve\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m try_solve\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_sympy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnumbers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m int_oo\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/torch/utils/_sympy/functions.py:7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01moperator\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msys\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msympy\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msympy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m S\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msympy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m sympify\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/sympy/__init__.py:74\u001b[39m\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlogic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (to_cnf, to_dnf, to_nnf, And, Or, Not, Xor, Nand, Nor,\n\u001b[32m     68\u001b[39m         Implies, Equivalent, ITE, POSform, SOPform, simplify_logic, bool_map,\n\u001b[32m     69\u001b[39m         true, false, satisfiable)\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01massumptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (AppliedPredicate, Predicate, AssumptionsContext,\n\u001b[32m     72\u001b[39m         assuming, Q, ask, register_handler, remove_handler, refine)\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpolys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (Poly, PurePoly, poly_from_expr, parallel_poly_from_expr,\n\u001b[32m     75\u001b[39m         degree, total_degree, degree_list, LC, LM, LT, pdiv, prem, pquo,\n\u001b[32m     76\u001b[39m         pexquo, div, rem, quo, exquo, half_gcdex, gcdex, invert,\n\u001b[32m     77\u001b[39m         subresultants, resultant, discriminant, cofactors, gcd_list, gcd,\n\u001b[32m     78\u001b[39m         lcm_list, lcm, terms_gcd, trunc, monic, content, primitive, compose,\n\u001b[32m     79\u001b[39m         decompose, sturm, gff_list, gff, sqf_norm, sqf_part, sqf_list, sqf,\n\u001b[32m     80\u001b[39m         factor_list, factor, intervals, refine_root, count_roots, all_roots,\n\u001b[32m     81\u001b[39m         real_roots, nroots, ground_roots, nth_power_roots_poly, cancel,\n\u001b[32m     82\u001b[39m         reduced, groebner, is_zero_dimensional, GroebnerBasis, poly,\n\u001b[32m     83\u001b[39m         symmetrize, horner, interpolate, rational_interpolate, viete, together,\n\u001b[32m     84\u001b[39m         BasePolynomialError, ExactQuotientFailed, PolynomialDivisionFailed,\n\u001b[32m     85\u001b[39m         OperationNotSupported, HeuristicGCDFailed, HomomorphismFailed,\n\u001b[32m     86\u001b[39m         IsomorphismFailed, ExtraneousFactors, EvaluationFailed,\n\u001b[32m     87\u001b[39m         RefinementFailed, CoercionFailed, NotInvertible, NotReversible,\n\u001b[32m     88\u001b[39m         NotAlgebraic, DomainError, PolynomialError, UnificationFailed,\n\u001b[32m     89\u001b[39m         GeneratorsError, GeneratorsNeeded, ComputationFailed,\n\u001b[32m     90\u001b[39m         UnivariatePolynomialError, MultivariatePolynomialError,\n\u001b[32m     91\u001b[39m         PolificationFailed, OptionError, FlagError, minpoly,\n\u001b[32m     92\u001b[39m         minimal_polynomial, primitive_element, field_isomorphism,\n\u001b[32m     93\u001b[39m         to_number_field, isolate, round_two, prime_decomp, prime_valuation,\n\u001b[32m     94\u001b[39m         galois_group, itermonomials, Monomial, lex, grlex,\n\u001b[32m     95\u001b[39m         grevlex, ilex, igrlex, igrevlex, CRootOf, rootof, RootOf,\n\u001b[32m     96\u001b[39m         ComplexRootOf, RootSum, roots, Domain, FiniteField, IntegerRing,\n\u001b[32m     97\u001b[39m         RationalField, RealField, ComplexField, PythonFiniteField,\n\u001b[32m     98\u001b[39m         GMPYFiniteField, PythonIntegerRing, GMPYIntegerRing, PythonRational,\n\u001b[32m     99\u001b[39m         GMPYRationalField, AlgebraicField, PolynomialRing, FractionField,\n\u001b[32m    100\u001b[39m         ExpressionDomain, FF_python, FF_gmpy, ZZ_python, ZZ_gmpy, QQ_python,\n\u001b[32m    101\u001b[39m         QQ_gmpy, GF, FF, ZZ, QQ, ZZ_I, QQ_I, RR, CC, EX, EXRAW,\n\u001b[32m    102\u001b[39m         construct_domain, swinnerton_dyer_poly, cyclotomic_poly,\n\u001b[32m    103\u001b[39m         symmetric_poly, random_poly, interpolating_poly, jacobi_poly,\n\u001b[32m    104\u001b[39m         chebyshevt_poly, chebyshevu_poly, hermite_poly, hermite_prob_poly,\n\u001b[32m    105\u001b[39m         legendre_poly, laguerre_poly, apart, apart_list, assemble_partfrac_list,\n\u001b[32m    106\u001b[39m         Options, ring, xring, vring, sring, field, xfield, vfield, sfield)\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mseries\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (Order, O, limit, Limit, gruntz, series, approximants,\n\u001b[32m    109\u001b[39m         residue, EmptySequence, SeqPer, SeqFormula, sequence, SeqAdd, SeqMul,\n\u001b[32m    110\u001b[39m         fourier_series, fps, difference_delta, limit_seq)\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunctions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (factorial, factorial2, rf, ff, binomial,\n\u001b[32m    113\u001b[39m         RisingFactorial, FallingFactorial, subfactorial, carmichael,\n\u001b[32m    114\u001b[39m         fibonacci, lucas, motzkin, tribonacci, harmonic, bernoulli, bell, euler,\n\u001b[32m   (...)\u001b[39m\u001b[32m    135\u001b[39m         Znm, elliptic_k, elliptic_f, elliptic_e, elliptic_pi, beta, mathieus,\n\u001b[32m    136\u001b[39m         mathieuc, mathieusprime, mathieucprime, riemann_xi, betainc, betainc_regularized)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/sympy/polys/__init__.py:124\u001b[39m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01morthopolys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (jacobi_poly, chebyshevt_poly, chebyshevu_poly,\n\u001b[32m    119\u001b[39m         hermite_poly, hermite_prob_poly, legendre_poly, laguerre_poly)\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mappellseqs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (bernoulli_poly, bernoulli_c_poly, genocchi_poly,\n\u001b[32m    122\u001b[39m         euler_poly, andre_poly)\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpartfrac\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m apart, apart_list, assemble_partfrac_list\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpolyoptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Options\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ring, xring, vring, sring\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/sympy/polys/partfrac.py:13\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msympy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpolys\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpolytools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m parallel_poly_from_expr\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msympy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutilities\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m numbered_symbols, take, xthreaded, public\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;129;43m@xthreaded\u001b[39;49m\n\u001b[32m     14\u001b[39m \u001b[38;5;129;43m@public\u001b[39;49m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[34;43mapart\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[38;5;250;43m    \u001b[39;49m\u001b[33;43;03m\"\"\"\u001b[39;49;00m\n\u001b[32m     17\u001b[39m \u001b[33;43;03m    Compute partial fraction decomposition of a rational function.\u001b[39;49;00m\n\u001b[32m     18\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     67\u001b[39m \u001b[33;43;03m    apart_list, assemble_partfrac_list\u001b[39;49;00m\n\u001b[32m     68\u001b[39m \u001b[33;43;03m    \"\"\"\u001b[39;49;00m\n\u001b[32m     69\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallowed_flags\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/sympy/utilities/decorator.py:76\u001b[39m, in \u001b[36mxthreaded\u001b[39m\u001b[34m(func)\u001b[39m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mxthreaded\u001b[39m(func):\n\u001b[32m     60\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Apply ``func`` to sub--elements of an object, excluding :class:`~.Add`.\u001b[39;00m\n\u001b[32m     61\u001b[39m \n\u001b[32m     62\u001b[39m \u001b[33;03m    This decorator is intended to make it uniformly possible to apply a\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     74\u001b[39m \n\u001b[32m     75\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mthreaded_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/sympy/utilities/decorator.py:13\u001b[39m, in \u001b[36mthreaded_factory\u001b[39m\u001b[34m(func, use_add)\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"A factory for ``threaded`` decorators. \"\"\"\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msympy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m sympify\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msympy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmatrices\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MatrixBase\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msympy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutilities\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01miterables\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m iterable\n\u001b[32m     16\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mthreaded_func\u001b[39m(expr, *args, **kwargs):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1360\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1331\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:935\u001b[39m, in \u001b[36m_load_unlocked\u001b[39m\u001b[34m(spec)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:995\u001b[39m, in \u001b[36mexec_module\u001b[39m\u001b[34m(self, module)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1091\u001b[39m, in \u001b[36mget_code\u001b[39m\u001b[34m(self, fullname)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1190\u001b[39m, in \u001b[36mget_data\u001b[39m\u001b[34m(self, path)\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import VLLM\n",
    "\n",
    "my_model = VLLM(\n",
    "    model=\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\n",
    "    trust_remote_code=True,\n",
    "    dtype='float16',\n",
    ")\n",
    "\n",
    "tuner_with_custom_llm = PromptTuner(model=my_model)\n",
    "tuner_with_custom_llm.run(start_prompt=\"Write an essay about autumn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0faf05ca",
   "metadata": {},
   "source": [
    "Or to change config of our default model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d0088a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-07-09 01:02:04,899] [INFO] [llm.init] - Initializing default model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 07-09 01:02:05 config.py:2448] Casting torch.bfloat16 to torch.float16.\n",
      "INFO 07-09 01:02:05 config.py:549] This model supports multiple tasks: {'classify', 'reward', 'generate', 'embed', 'score'}. Defaulting to 'generate'.\n",
      "INFO 07-09 01:02:05 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='t-tech/T-lite-it-1.0', speculative_config=None, tokenizer='t-tech/T-lite-it-1.0', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=32768, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=t-tech/T-lite-it-1.0, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"splitting_ops\":[],\"compile_sizes\":[],\"cudagraph_capture_sizes\":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":256}, use_cached_outputs=False, \n",
      "INFO 07-09 01:02:06 model_runner.py:1110] Starting to load model t-tech/T-lite-it-1.0...\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 23.64 GiB of which 11.56 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 23.17 GiB is allocated by PyTorch, with 46.00 MiB allocated in private pools (e.g., CUDA Graphs), and 81.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcoolprompt\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlanguage_model\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mllm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DefaultLLM\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m changed_model = \u001b[43mDefaultLLM\u001b[49m\u001b[43m.\u001b[49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlangchain_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmax_new_tokens\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m tuner_with_changed_llm = PromptTuner(model=changed_model)\n\u001b[32m      9\u001b[39m tuner_with_changed_llm.run(start_prompt=\u001b[33m\"\u001b[39m\u001b[33mWrite an essay about autumn\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/tank/scratch/asitkina/CoolPrompt/coolprompt/language_model/llm.py:51\u001b[39m, in \u001b[36mDefaultLLM.init\u001b[39m\u001b[34m(langchain_config, vllm_engine_config)\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m langchain_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     49\u001b[39m     generation_and_model_config.update(langchain_config)\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVLLM\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDEFAULT_MODEL_NAME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfloat16\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvllm_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvllm_engine_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mgeneration_and_model_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/langchain_core/load/serializable.py:130\u001b[39m, in \u001b[36mSerializable.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    129\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: D419\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[31m[... skipping hidden 1 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/pydantic/_internal/_decorators_v1.py:148\u001b[39m, in \u001b[36mmake_v1_generic_root_validator.<locals>._wrapper1\u001b[39m\u001b[34m(values, _)\u001b[39m\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_wrapper1\u001b[39m(values: RootValidatorValues, _: core_schema.ValidationInfo) -> RootValidatorValues:\n\u001b[32m--> \u001b[39m\u001b[32m148\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvalidator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/langchain_core/utils/pydantic.py:226\u001b[39m, in \u001b[36mpre_init.<locals>.wrapper\u001b[39m\u001b[34m(cls, values)\u001b[39m\n\u001b[32m    223\u001b[39m             values[name] = field_info.default\n\u001b[32m    225\u001b[39m \u001b[38;5;66;03m# Call the decorated function\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m226\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/langchain_community/llms/vllm.py:89\u001b[39m, in \u001b[36mVLLM.validate_environment\u001b[39m\u001b[34m(cls, values)\u001b[39m\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m     84\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m     85\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCould not import vllm python package. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     86\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease install it with `pip install vllm`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     87\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m values[\u001b[33m\"\u001b[39m\u001b[33mclient\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mVLLModel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensor_parallel_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtensor_parallel_size\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrust_remote_code\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     93\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdtype\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdownload_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdownload_dir\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvllm_kwargs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m values\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/vllm/utils.py:1022\u001b[39m, in \u001b[36mdeprecate_args.<locals>.wrapper.<locals>.inner\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1015\u001b[39m             msg += \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00madditional_message\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1017\u001b[39m         warnings.warn(\n\u001b[32m   1018\u001b[39m             \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m(msg),\n\u001b[32m   1019\u001b[39m             stacklevel=\u001b[32m3\u001b[39m,  \u001b[38;5;66;03m# The inner function takes up one level\u001b[39;00m\n\u001b[32m   1020\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1022\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/vllm/entrypoints/llm.py:242\u001b[39m, in \u001b[36mLLM.__init__\u001b[39m\u001b[34m(self, model, tokenizer, tokenizer_mode, skip_tokenizer_init, trust_remote_code, allowed_local_media_path, tensor_parallel_size, dtype, quantization, revision, tokenizer_revision, seed, gpu_memory_utilization, swap_space, cpu_offload_gb, enforce_eager, max_seq_len_to_capture, disable_custom_all_reduce, disable_async_output_proc, hf_overrides, mm_processor_kwargs, task, override_pooler_config, compilation_config, **kwargs)\u001b[39m\n\u001b[32m    239\u001b[39m \u001b[38;5;66;03m# Logic to switch between engines is done at runtime instead of import\u001b[39;00m\n\u001b[32m    240\u001b[39m \u001b[38;5;66;03m# to avoid import order issues\u001b[39;00m\n\u001b[32m    241\u001b[39m \u001b[38;5;28mself\u001b[39m.engine_class = \u001b[38;5;28mself\u001b[39m.get_engine_class()\n\u001b[32m--> \u001b[39m\u001b[32m242\u001b[39m \u001b[38;5;28mself\u001b[39m.llm_engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_engine_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    243\u001b[39m \u001b[43m    \u001b[49m\u001b[43mengine_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musage_context\u001b[49m\u001b[43m=\u001b[49m\u001b[43mUsageContext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLLM_CLASS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    245\u001b[39m \u001b[38;5;28mself\u001b[39m.request_counter = Counter()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/vllm/engine/llm_engine.py:489\u001b[39m, in \u001b[36mLLMEngine.from_engine_args\u001b[39m\u001b[34m(cls, engine_args, usage_context, stat_loggers)\u001b[39m\n\u001b[32m    487\u001b[39m executor_class = \u001b[38;5;28mcls\u001b[39m._get_executor_cls(engine_config)\n\u001b[32m    488\u001b[39m \u001b[38;5;66;03m# Create the LLM engine.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m489\u001b[39m engine = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexecutor_class\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexecutor_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlog_stats\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mengine_args\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdisable_log_stats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m    \u001b[49m\u001b[43musage_context\u001b[49m\u001b[43m=\u001b[49m\u001b[43musage_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstat_loggers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstat_loggers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m engine\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/vllm/engine/llm_engine.py:273\u001b[39m, in \u001b[36mLLMEngine.__init__\u001b[39m\u001b[34m(self, vllm_config, executor_class, log_stats, usage_context, stat_loggers, input_registry, mm_registry, use_cached_outputs)\u001b[39m\n\u001b[32m    269\u001b[39m \u001b[38;5;28mself\u001b[39m.input_registry = input_registry\n\u001b[32m    270\u001b[39m \u001b[38;5;28mself\u001b[39m.input_processor = input_registry.create_input_processor(\n\u001b[32m    271\u001b[39m     \u001b[38;5;28mself\u001b[39m.model_config)\n\u001b[32m--> \u001b[39m\u001b[32m273\u001b[39m \u001b[38;5;28mself\u001b[39m.model_executor = \u001b[43mexecutor_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    275\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model_config.runner_type != \u001b[33m\"\u001b[39m\u001b[33mpooling\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    276\u001b[39m     \u001b[38;5;28mself\u001b[39m._initialize_kv_caches()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/vllm/executor/executor_base.py:52\u001b[39m, in \u001b[36mExecutorBase.__init__\u001b[39m\u001b[34m(self, vllm_config)\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;28mself\u001b[39m.prompt_adapter_config = vllm_config.prompt_adapter_config\n\u001b[32m     51\u001b[39m \u001b[38;5;28mself\u001b[39m.observability_config = vllm_config.observability_config\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_init_executor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[38;5;28mself\u001b[39m.is_sleeping = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/vllm/executor/uniproc_executor.py:47\u001b[39m, in \u001b[36mUniProcExecutor._init_executor\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;28mself\u001b[39m.collective_rpc(\u001b[33m\"\u001b[39m\u001b[33minit_worker\u001b[39m\u001b[33m\"\u001b[39m, args=([kwargs], ))\n\u001b[32m     46\u001b[39m \u001b[38;5;28mself\u001b[39m.collective_rpc(\u001b[33m\"\u001b[39m\u001b[33minit_device\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcollective_rpc\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mload_model\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/vllm/executor/uniproc_executor.py:56\u001b[39m, in \u001b[36mUniProcExecutor.collective_rpc\u001b[39m\u001b[34m(self, method, timeout, args, kwargs)\u001b[39m\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     55\u001b[39m     kwargs = {}\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m answer = \u001b[43mrun_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdriver_worker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m [answer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/vllm/utils.py:2196\u001b[39m, in \u001b[36mrun_method\u001b[39m\u001b[34m(obj, method, args, kwargs)\u001b[39m\n\u001b[32m   2194\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2195\u001b[39m     func = partial(method, obj)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2196\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/vllm/worker/worker.py:183\u001b[39m, in \u001b[36mWorker.load_model\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    181\u001b[39m     context = nullcontext()\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_runner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/vllm/worker/model_runner.py:1112\u001b[39m, in \u001b[36mGPUModelRunnerBase.load_model\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1110\u001b[39m logger.info(\u001b[33m\"\u001b[39m\u001b[33mStarting to load model \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m.model_config.model)\n\u001b[32m   1111\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m DeviceMemoryProfiler(\u001b[38;5;28mself\u001b[39m.device) \u001b[38;5;28;01mas\u001b[39;00m m:\n\u001b[32m-> \u001b[39m\u001b[32m1112\u001b[39m     \u001b[38;5;28mself\u001b[39m.model = \u001b[43mget_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1114\u001b[39m \u001b[38;5;28mself\u001b[39m.model_memory_usage = m.consumed_memory\n\u001b[32m   1115\u001b[39m logger.info(\u001b[33m\"\u001b[39m\u001b[33mLoading model weights took \u001b[39m\u001b[38;5;132;01m%.4f\u001b[39;00m\u001b[33m GB\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1116\u001b[39m             \u001b[38;5;28mself\u001b[39m.model_memory_usage / \u001b[38;5;28mfloat\u001b[39m(\u001b[32m2\u001b[39m**\u001b[32m30\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/vllm/model_executor/model_loader/__init__.py:14\u001b[39m, in \u001b[36mget_model\u001b[39m\u001b[34m(vllm_config)\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_model\u001b[39m(*, vllm_config: VllmConfig) -> nn.Module:\n\u001b[32m     13\u001b[39m     loader = get_model_loader(vllm_config.load_config)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/vllm/model_executor/model_loader/loader.py:406\u001b[39m, in \u001b[36mDefaultModelLoader.load_model\u001b[39m\u001b[34m(self, vllm_config)\u001b[39m\n\u001b[32m    404\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m set_default_torch_dtype(model_config.dtype):\n\u001b[32m    405\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m target_device:\n\u001b[32m--> \u001b[39m\u001b[32m406\u001b[39m         model = \u001b[43m_initialize_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    408\u001b[39m     weights_to_load = {name \u001b[38;5;28;01mfor\u001b[39;00m name, _ \u001b[38;5;129;01min\u001b[39;00m model.named_parameters()}\n\u001b[32m    409\u001b[39m     loaded_weights = model.load_weights(\n\u001b[32m    410\u001b[39m         \u001b[38;5;28mself\u001b[39m._get_all_weights(model_config, model))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/vllm/model_executor/model_loader/loader.py:125\u001b[39m, in \u001b[36m_initialize_model\u001b[39m\u001b[34m(vllm_config, prefix)\u001b[39m\n\u001b[32m    122\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mvllm_config\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m all_params \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mprefix\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m all_params:\n\u001b[32m    123\u001b[39m     \u001b[38;5;66;03m# new-style model class\u001b[39;00m\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_current_vllm_config(vllm_config, check_compile=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    127\u001b[39m msg = (\u001b[33m\"\u001b[39m\u001b[33mvLLM model class should accept `vllm_config` and `prefix` as \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    128\u001b[39m        \u001b[33m\"\u001b[39m\u001b[33minput arguments. Possibly you have an old-style model class\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    129\u001b[39m        \u001b[33m\"\u001b[39m\u001b[33m registered from out of tree and it is used for new vLLM version. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    130\u001b[39m        \u001b[33m\"\u001b[39m\u001b[33mCheck https://docs.vllm.ai/en/latest/design/arch_overview.html \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    131\u001b[39m        \u001b[33m\"\u001b[39m\u001b[33mfor the design and update the model class accordingly.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    132\u001b[39m warnings.warn(msg, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py:453\u001b[39m, in \u001b[36mQwen2ForCausalLM.__init__\u001b[39m\u001b[34m(self, vllm_config, prefix)\u001b[39m\n\u001b[32m    450\u001b[39m \u001b[38;5;28mself\u001b[39m.lora_config = lora_config\n\u001b[32m    452\u001b[39m \u001b[38;5;28mself\u001b[39m.quant_config = quant_config\n\u001b[32m--> \u001b[39m\u001b[32m453\u001b[39m \u001b[38;5;28mself\u001b[39m.model = \u001b[43mQwen2Model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    454\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_prefix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    456\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m get_pp_group().is_last_rank:\n\u001b[32m    457\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m config.tie_word_embeddings:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/vllm/compilation/decorators.py:151\u001b[39m, in \u001b[36m_support_torch_compile.<locals>.__init__\u001b[39m\u001b[34m(self, vllm_config, prefix, **kwargs)\u001b[39m\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *, vllm_config: VllmConfig, prefix: \u001b[38;5;28mstr\u001b[39m = \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m151\u001b[39m     \u001b[43mold_init\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    152\u001b[39m     \u001b[38;5;28mself\u001b[39m.vllm_config = vllm_config\n\u001b[32m    153\u001b[39m     \u001b[38;5;66;03m# for CompilationLevel.DYNAMO_AS_IS , the upper level model runner\u001b[39;00m\n\u001b[32m    154\u001b[39m     \u001b[38;5;66;03m# will handle the compilation, so we don't need to do anything here.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py:307\u001b[39m, in \u001b[36mQwen2Model.__init__\u001b[39m\u001b[34m(self, vllm_config, prefix)\u001b[39m\n\u001b[32m    304\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    305\u001b[39m     \u001b[38;5;28mself\u001b[39m.embed_tokens = PPMissingLayer()\n\u001b[32m--> \u001b[39m\u001b[32m307\u001b[39m \u001b[38;5;28mself\u001b[39m.start_layer, \u001b[38;5;28mself\u001b[39m.end_layer, \u001b[38;5;28mself\u001b[39m.layers = \u001b[43mmake_layers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    308\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnum_hidden_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    309\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mQwen2DecoderLayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    310\u001b[39m \u001b[43m                                     \u001b[49m\u001b[43mcache_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[43m                                     \u001b[49m\u001b[43mquant_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquant_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[43m                                     \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    313\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mprefix\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m.layers\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[38;5;28mself\u001b[39m.make_empty_intermediate_tensors = (\n\u001b[32m    317\u001b[39m     make_empty_intermediate_tensors_factory(\n\u001b[32m    318\u001b[39m         [\u001b[33m\"\u001b[39m\u001b[33mhidden_states\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mresidual\u001b[39m\u001b[33m\"\u001b[39m], config.hidden_size))\n\u001b[32m    319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m get_pp_group().is_last_rank:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/vllm/model_executor/models/utils.py:558\u001b[39m, in \u001b[36mmake_layers\u001b[39m\u001b[34m(num_hidden_layers, layer_fn, prefix)\u001b[39m\n\u001b[32m    552\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistributed\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_pp_indices\n\u001b[32m    553\u001b[39m start_layer, end_layer = get_pp_indices(num_hidden_layers,\n\u001b[32m    554\u001b[39m                                         get_pp_group().rank_in_group,\n\u001b[32m    555\u001b[39m                                         get_pp_group().world_size)\n\u001b[32m    556\u001b[39m modules = torch.nn.ModuleList(\n\u001b[32m    557\u001b[39m     [PPMissingLayer() \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_layer)] + [\n\u001b[32m--> \u001b[39m\u001b[32m558\u001b[39m         maybe_offload_to_cpu(\u001b[43mlayer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mprefix\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m.\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43midx\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[32m    559\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_layer, end_layer)\n\u001b[32m    560\u001b[39m     ] + [PPMissingLayer() \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(end_layer, num_hidden_layers)])\n\u001b[32m    561\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m start_layer, end_layer, modules\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py:309\u001b[39m, in \u001b[36mQwen2Model.__init__.<locals>.<lambda>\u001b[39m\u001b[34m(prefix)\u001b[39m\n\u001b[32m    304\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    305\u001b[39m     \u001b[38;5;28mself\u001b[39m.embed_tokens = PPMissingLayer()\n\u001b[32m    307\u001b[39m \u001b[38;5;28mself\u001b[39m.start_layer, \u001b[38;5;28mself\u001b[39m.end_layer, \u001b[38;5;28mself\u001b[39m.layers = make_layers(\n\u001b[32m    308\u001b[39m     config.num_hidden_layers,\n\u001b[32m--> \u001b[39m\u001b[32m309\u001b[39m     \u001b[38;5;28;01mlambda\u001b[39;00m prefix: \u001b[43mQwen2DecoderLayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    310\u001b[39m \u001b[43m                                     \u001b[49m\u001b[43mcache_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[43m                                     \u001b[49m\u001b[43mquant_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquant_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[43m                                     \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    313\u001b[39m     prefix=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.layers\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    314\u001b[39m )\n\u001b[32m    316\u001b[39m \u001b[38;5;28mself\u001b[39m.make_empty_intermediate_tensors = (\n\u001b[32m    317\u001b[39m     make_empty_intermediate_tensors_factory(\n\u001b[32m    318\u001b[39m         [\u001b[33m\"\u001b[39m\u001b[33mhidden_states\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mresidual\u001b[39m\u001b[33m\"\u001b[39m], config.hidden_size))\n\u001b[32m    319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m get_pp_group().is_last_rank:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py:208\u001b[39m, in \u001b[36mQwen2DecoderLayer.__init__\u001b[39m\u001b[34m(self, config, cache_config, quant_config, prefix)\u001b[39m\n\u001b[32m    205\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    206\u001b[39m     attn_type = AttentionType.ENCODER_ONLY\n\u001b[32m--> \u001b[39m\u001b[32m208\u001b[39m \u001b[38;5;28mself\u001b[39m.self_attn = \u001b[43mQwen2Attention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    209\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_size\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhidden_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnum_attention_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmax_position_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_kv_heads\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnum_key_value_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    213\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrope_theta\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrope_theta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquant_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquant_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    216\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrope_scaling\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrope_scaling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mprefix\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m.self_attn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattn_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattn_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    220\u001b[39m \u001b[38;5;28mself\u001b[39m.mlp = Qwen2MLP(\n\u001b[32m    221\u001b[39m     hidden_size=\u001b[38;5;28mself\u001b[39m.hidden_size,\n\u001b[32m    222\u001b[39m     intermediate_size=config.intermediate_size,\n\u001b[32m   (...)\u001b[39m\u001b[32m    225\u001b[39m     prefix=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.mlp\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m )\n\u001b[32m    227\u001b[39m \u001b[38;5;28mself\u001b[39m.input_layernorm = RMSNorm(config.hidden_size,\n\u001b[32m    228\u001b[39m                                eps=config.rms_norm_eps)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py:136\u001b[39m, in \u001b[36mQwen2Attention.__init__\u001b[39m\u001b[34m(self, hidden_size, num_heads, num_kv_heads, max_position, rope_theta, cache_config, quant_config, rope_scaling, prefix, attn_type)\u001b[39m\n\u001b[32m    133\u001b[39m \u001b[38;5;28mself\u001b[39m.scaling = \u001b[38;5;28mself\u001b[39m.head_dim**-\u001b[32m0.5\u001b[39m\n\u001b[32m    134\u001b[39m \u001b[38;5;28mself\u001b[39m.rope_theta = rope_theta\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m \u001b[38;5;28mself\u001b[39m.qkv_proj = \u001b[43mQKVParallelLinear\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhead_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtotal_num_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtotal_num_kv_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquant_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquant_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mprefix\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m.qkv_proj\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    144\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    145\u001b[39m \u001b[38;5;28mself\u001b[39m.o_proj = RowParallelLinear(\n\u001b[32m    146\u001b[39m     \u001b[38;5;28mself\u001b[39m.total_num_heads * \u001b[38;5;28mself\u001b[39m.head_dim,\n\u001b[32m    147\u001b[39m     hidden_size,\n\u001b[32m   (...)\u001b[39m\u001b[32m    150\u001b[39m     prefix=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.o_proj\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    151\u001b[39m )\n\u001b[32m    153\u001b[39m \u001b[38;5;28mself\u001b[39m.rotary_emb = get_rope(\n\u001b[32m    154\u001b[39m     \u001b[38;5;28mself\u001b[39m.head_dim,\n\u001b[32m    155\u001b[39m     rotary_dim=\u001b[38;5;28mself\u001b[39m.head_dim,\n\u001b[32m   (...)\u001b[39m\u001b[32m    158\u001b[39m     rope_scaling=rope_scaling,\n\u001b[32m    159\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py:736\u001b[39m, in \u001b[36mQKVParallelLinear.__init__\u001b[39m\u001b[34m(self, hidden_size, head_size, total_num_heads, total_num_kv_heads, bias, skip_bias_add, params_dtype, quant_config, prefix)\u001b[39m\n\u001b[32m    728\u001b[39m output_size = (\u001b[38;5;28mself\u001b[39m.num_heads +\n\u001b[32m    729\u001b[39m                \u001b[32m2\u001b[39m * \u001b[38;5;28mself\u001b[39m.num_kv_heads) * tp_size * \u001b[38;5;28mself\u001b[39m.head_size\n\u001b[32m    730\u001b[39m \u001b[38;5;28mself\u001b[39m.output_sizes = [\n\u001b[32m    731\u001b[39m     \u001b[38;5;28mself\u001b[39m.num_heads * \u001b[38;5;28mself\u001b[39m.head_size * tp_size,  \u001b[38;5;66;03m# q_proj\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28mself\u001b[39m.num_kv_heads * \u001b[38;5;28mself\u001b[39m.head_size * tp_size,  \u001b[38;5;66;03m# k_proj\u001b[39;00m\n\u001b[32m    733\u001b[39m     \u001b[38;5;28mself\u001b[39m.num_kv_heads * \u001b[38;5;28mself\u001b[39m.head_size * tp_size,  \u001b[38;5;66;03m# v_proj \u001b[39;00m\n\u001b[32m    734\u001b[39m ]\n\u001b[32m--> \u001b[39m\u001b[32m736\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minput_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    737\u001b[39m \u001b[43m                 \u001b[49m\u001b[43moutput_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    738\u001b[39m \u001b[43m                 \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    739\u001b[39m \u001b[43m                 \u001b[49m\u001b[43mgather_output\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    740\u001b[39m \u001b[43m                 \u001b[49m\u001b[43mskip_bias_add\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskip_bias_add\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    741\u001b[39m \u001b[43m                 \u001b[49m\u001b[43mparams_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    742\u001b[39m \u001b[43m                 \u001b[49m\u001b[43mquant_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquant_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    743\u001b[39m \u001b[43m                 \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py:314\u001b[39m, in \u001b[36mColumnParallelLinear.__init__\u001b[39m\u001b[34m(self, input_size, output_size, bias, gather_output, skip_bias_add, params_dtype, quant_config, output_sizes, prefix)\u001b[39m\n\u001b[32m    311\u001b[39m     output_sizes = [output_size]\n\u001b[32m    313\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.quant_method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m314\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mquant_method\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_weights\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    315\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_size_per_partition\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minput_size_per_partition\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_partition_sizes\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moutput_partition_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_size\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minput_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    319\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_size\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moutput_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    320\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparams_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    321\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    322\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight_loader_v2\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mquant_method\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__class__\u001b[39;49m\u001b[43m.\u001b[49m\u001b[34;43m__name__\u001b[39;49m\n\u001b[32m    323\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mWEIGHT_LOADER_V2_SUPPORTED\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    324\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m bias:\n\u001b[32m    325\u001b[39m     \u001b[38;5;28mself\u001b[39m.bias = Parameter(\n\u001b[32m    326\u001b[39m         torch.empty(\u001b[38;5;28mself\u001b[39m.output_size_per_partition,\n\u001b[32m    327\u001b[39m                     dtype=params_dtype))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py:129\u001b[39m, in \u001b[36mUnquantizedLinearMethod.create_weights\u001b[39m\u001b[34m(self, layer, input_size_per_partition, output_partition_sizes, input_size, output_size, params_dtype, **extra_weight_attrs)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate_weights\u001b[39m(\u001b[38;5;28mself\u001b[39m, layer: torch.nn.Module,\n\u001b[32m    125\u001b[39m                    input_size_per_partition: \u001b[38;5;28mint\u001b[39m,\n\u001b[32m    126\u001b[39m                    output_partition_sizes: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mint\u001b[39m], input_size: \u001b[38;5;28mint\u001b[39m,\n\u001b[32m    127\u001b[39m                    output_size: \u001b[38;5;28mint\u001b[39m, params_dtype: torch.dtype,\n\u001b[32m    128\u001b[39m                    **extra_weight_attrs):\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m     weight = Parameter(\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput_partition_sizes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    130\u001b[39m \u001b[43m                                   \u001b[49m\u001b[43minput_size_per_partition\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    131\u001b[39m \u001b[43m                                   \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams_dtype\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    132\u001b[39m                        requires_grad=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    133\u001b[39m     set_weight_attrs(weight, {\u001b[33m\"\u001b[39m\u001b[33minput_dim\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m1\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33moutput_dim\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m0\u001b[39m})\n\u001b[32m    134\u001b[39m     layer.register_parameter(\u001b[33m\"\u001b[39m\u001b[33mweight\u001b[39m\u001b[33m\"\u001b[39m, weight)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/torch/utils/_device.py:106\u001b[39m, in \u001b[36mDeviceContext.__torch_function__\u001b[39m\u001b[34m(self, func, types, args, kwargs)\u001b[39m\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m _device_constructors() \u001b[38;5;129;01mand\u001b[39;00m kwargs.get(\u001b[33m'\u001b[39m\u001b[33mdevice\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    105\u001b[39m     kwargs[\u001b[33m'\u001b[39m\u001b[33mdevice\u001b[39m\u001b[33m'\u001b[39m] = \u001b[38;5;28mself\u001b[39m.device\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 23.64 GiB of which 11.56 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 23.17 GiB is allocated by PyTorch, with 46.00 MiB allocated in private pools (e.g., CUDA Graphs), and 81.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "from coolprompt.language_model.llm import DefaultLLM\n",
    "\n",
    "changed_model = DefaultLLM.init(langchain_config={\n",
    "    'max_new_tokens': 1000,\n",
    "    \"temperature\": 0.0,\n",
    "})\n",
    "\n",
    "tuner_with_changed_llm = PromptTuner(model=changed_model)\n",
    "tuner_with_changed_llm.run(start_prompt=\"Write an essay about autumn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43396516",
   "metadata": {},
   "source": [
    "You can access prompts and their metrics via tuner fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eedc8a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start prompt: Summarize this text\n",
      "Final prompt: Please provide a concise summary of the text, focusing on the main points and omitting any unnecessary details.\n",
      "Start prompt metric:  0.2889385547946554\n",
      "Final prompt metric:  0.30479966549868787\n"
     ]
    }
   ],
   "source": [
    "def print_results(tuner):\n",
    "    print(\"Start prompt:\", tuner.init_prompt)\n",
    "    print(\"Final prompt:\", tuner.final_prompt)\n",
    "    print(\"Start prompt metric: \", tuner.init_metric)\n",
    "    print(\"Final prompt metric: \", tuner.final_metric)\n",
    "\n",
    "print_results(tuner)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80de1822",
   "metadata": {},
   "source": [
    "There are 3 currently implemented optimizers:\n",
    "- HyPE (optimizing with predefined system instruction)\n",
    "- DistillPrompt\n",
    "- ReflectivePrompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77cc66b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-07-09 01:11:35,596] [INFO] [assistant.run] - Validating args for PromptTuner running\n",
      "[2025-07-09 01:11:36,329] [INFO] [evaluator.__init__] - Evaluator sucessfully initialized with f1 metric\n",
      "[2025-07-09 01:11:36,330] [INFO] [assistant.run] - === Starting Prompt Optimization ===\n",
      "[2025-07-09 01:11:36,330] [INFO] [assistant.run] - Method: hype, Task: classification\n",
      "[2025-07-09 01:11:36,331] [INFO] [assistant.run] - Metric: f1, Validation size: 0.25\n",
      "[2025-07-09 01:11:36,332] [INFO] [assistant.run] - Dataset: 100 samples\n",
      "[2025-07-09 01:11:36,332] [INFO] [assistant.run] - Target: 100 samples\n",
      "[2025-07-09 01:11:36,333] [INFO] [hype.hype_optimizer] - Running HyPE optimization...\n",
      "Processed prompts: 100%|█| 1/1 [00:00<00:00,  1.29it/s, est. speed input: 320.47 toks/s, out\n",
      "[2025-07-09 01:11:37,114] [INFO] [hype.hype_optimizer] - HyPE optimization completed\n",
      "[2025-07-09 01:11:37,115] [INFO] [assistant.run] - Evaluating on given dataset for classification task...\n",
      "[2025-07-09 01:11:37,115] [INFO] [evaluator.evaluate] - Evaluating prompt for classification task on 100 samples\n",
      "Processed prompts: 100%|█| 100/100 [01:48<00:00,  1.09s/it, est. speed input: 275.90 toks/s,\n",
      "[2025-07-09 01:13:25,746] [INFO] [evaluator.evaluate] - Evaluating prompt for classification task on 100 samples\n",
      "Processed prompts: 100%|█| 100/100 [00:05<00:00, 17.36it/s, est. speed input: 5388.44 toks/s\n",
      "[2025-07-09 01:13:31,896] [INFO] [assistant.run] - Initial f1 score: 0.6364983164983165, final f1 score: 0.8899889988998899\n",
      "[2025-07-09 01:13:31,897] [INFO] [assistant.run] - === Prompt Optimization Completed ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start prompt: Classify sentence sentiment\n",
      "Final prompt: Please provide a sentence and classify its sentiment as positive, negative, or neutral.\n",
      "Start prompt metric:  0.6364983164983165\n",
      "Final prompt metric:  0.8899889988998899\n"
     ]
    }
   ],
   "source": [
    "tuner.run(\n",
    "    start_prompt=class_start_prompt,\n",
    "    task=\"classification\",\n",
    "    method=\"hype\",\n",
    "    dataset=class_dataset,\n",
    "    target=class_targets,\n",
    "    metric=\"f1\"\n",
    ")\n",
    "\n",
    "print_results(tuner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62164ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-07-09 01:13:32,056] [INFO] [assistant.run] - Validating args for PromptTuner running\n",
      "[2025-07-09 01:13:32,794] [INFO] [evaluator.__init__] - Evaluator sucessfully initialized with f1 metric\n",
      "[2025-07-09 01:13:32,795] [INFO] [assistant.run] - === Starting Prompt Optimization ===\n",
      "[2025-07-09 01:13:32,795] [INFO] [assistant.run] - Method: distill, Task: classification\n",
      "[2025-07-09 01:13:32,796] [INFO] [assistant.run] - Metric: f1, Validation size: 0.25\n",
      "[2025-07-09 01:13:32,796] [INFO] [assistant.run] - Dataset: 10 samples\n",
      "[2025-07-09 01:13:32,797] [INFO] [assistant.run] - Target: 10 samples\n",
      "[2025-07-09 01:13:32,809] [INFO] [distiller.distillation] - Starting DistillPrompt optimization...\n",
      "[2025-07-09 01:13:32,810] [INFO] [evaluator.evaluate] - Evaluating prompt for classification task on 7 samples\n",
      "Processed prompts: 100%|█| 7/7 [01:51<00:00, 15.91s/it, est. speed input: 2.96 toks/s, outpu\n",
      "  0%|                                                                 | 0/1 [00:00<?, ?it/s][2025-07-09 01:15:24,232] [INFO] [distiller.distillation] - Starting round 0\n",
      "Processed prompts: 100%|█| 4/4 [00:01<00:00,  3.99it/s, est. speed input: 446.88 toks/s, out\n",
      "[2025-07-09 01:15:25,241] [INFO] [evaluator.evaluate] - Evaluating prompt for classification task on 7 samples\n",
      "Processed prompts: 100%|█| 7/7 [00:00<00:00, 14.05it/s, est. speed input: 873.31 toks/s, out\n",
      "[2025-07-09 01:15:25,757] [INFO] [evaluator.evaluate] - Evaluating prompt for classification task on 7 samples\n",
      "Processed prompts: 100%|█| 7/7 [00:02<00:00,  3.47it/s, est. speed input: 243.72 toks/s, out\n",
      "[2025-07-09 01:15:27,792] [INFO] [evaluator.evaluate] - Evaluating prompt for classification task on 7 samples\n",
      "Processed prompts: 100%|█| 7/7 [01:43<00:00, 14.85s/it, est. speed input: 4.18 toks/s, outpu\n",
      "[2025-07-09 01:17:11,777] [INFO] [evaluator.evaluate] - Evaluating prompt for classification task on 7 samples\n",
      "Processed prompts: 100%|█| 7/7 [01:43<00:00, 14.82s/it, est. speed input: 4.46 toks/s, outpu\n",
      "Processed prompts: 100%|█| 4/4 [00:05<00:00,  1.44s/it, est. speed input: 175.79 toks/s, out\n",
      "[2025-07-09 01:19:01,333] [INFO] [evaluator.evaluate] - Evaluating prompt for classification task on 7 samples\n",
      "Processed prompts: 100%|█| 7/7 [00:00<00:00, 13.99it/s, est. speed input: 869.28 toks/s, out\n",
      "[2025-07-09 01:19:01,852] [INFO] [evaluator.evaluate] - Evaluating prompt for classification task on 7 samples\n",
      "Processed prompts: 100%|█| 7/7 [00:00<00:00,  9.77it/s, est. speed input: 2395.57 toks/s, ou\n",
      "[2025-07-09 01:19:02,588] [INFO] [evaluator.evaluate] - Evaluating prompt for classification task on 7 samples\n",
      "Processed prompts: 100%|█| 7/7 [01:44<00:00, 14.86s/it, est. speed input: 4.18 toks/s, outpu\n",
      "[2025-07-09 01:20:46,654] [INFO] [evaluator.evaluate] - Evaluating prompt for classification task on 7 samples\n",
      "Processed prompts: 100%|█| 7/7 [01:43<00:00, 14.83s/it, est. speed input: 4.46 toks/s, outpu\n",
      "Processed prompts: 100%|█| 4/4 [01:52<00:00, 28.13s/it, est. speed input: 5.71 toks/s, outpu\n",
      "[2025-07-09 01:24:23,009] [INFO] [evaluator.evaluate] - Evaluating prompt for classification task on 7 samples\n",
      "Processed prompts: 100%|█| 7/7 [00:00<00:00, 20.63it/s, est. speed input: 1839.83 toks/s, ou\n",
      "[2025-07-09 01:24:23,367] [INFO] [evaluator.evaluate] - Evaluating prompt for classification task on 7 samples\n",
      "Processed prompts: 100%|█| 7/7 [01:51<00:00, 15.98s/it, est. speed input: 5.83 toks/s, outpu\n",
      "[2025-07-09 01:26:15,218] [INFO] [evaluator.evaluate] - Evaluating prompt for classification task on 7 samples\n",
      "Processed prompts: 100%|█| 7/7 [00:00<00:00, 19.64it/s, est. speed input: 1869.36 toks/s, ou\n",
      "[2025-07-09 01:26:15,598] [INFO] [evaluator.evaluate] - Evaluating prompt for classification task on 7 samples\n",
      "Processed prompts: 100%|█| 7/7 [01:43<00:00, 14.84s/it, est. speed input: 4.46 toks/s, outpu\n",
      "Processed prompts: 100%|█| 1/1 [00:02<00:00,  2.27s/it, est. speed input: 120.53 toks/s, out\n",
      "[2025-07-09 01:28:01,794] [INFO] [evaluator.evaluate] - Evaluating prompt for classification task on 7 samples\n",
      "Processed prompts: 100%|█| 7/7 [00:00<00:00, 12.06it/s, est. speed input: 1449.53 toks/s, ou\n",
      "Processed prompts: 100%|█| 3/3 [01:44<00:00, 34.71s/it, est. speed input: 2.74 toks/s, outpu\n",
      "[2025-07-09 01:29:46,529] [INFO] [evaluator.evaluate] - Evaluating prompt for classification task on 7 samples\n",
      "Processed prompts: 100%|█| 7/7 [01:52<00:00, 16.06s/it, est. speed input: 16.38 toks/s, outp\n",
      "[2025-07-09 01:31:38,999] [INFO] [evaluator.evaluate] - Evaluating prompt for classification task on 7 samples\n",
      "Processed prompts: 100%|█| 7/7 [02:21<00:00, 20.27s/it, est. speed input: 199.46 toks/s, out\n",
      "[2025-07-09 01:34:00,930] [INFO] [evaluator.evaluate] - Evaluating prompt for classification task on 7 samples\n",
      "Processed prompts: 100%|█| 7/7 [00:00<00:00, 13.47it/s, est. speed input: 2251.45 toks/s, ou\n",
      "[2025-07-09 01:34:01,470] [INFO] [distiller.distillation] - Best candidate score in round 0: 1.0\n",
      "100%|███████████████████████████████████████████████████████| 1/1 [18:37<00:00, 1117.24s/it]\n",
      "[2025-07-09 01:34:01,471] [INFO] [evaluator.evaluate] - Evaluating prompt for classification task on 3 samples\n",
      "Processed prompts: 100%|█| 3/3 [00:00<00:00, 10.64it/s, est. speed input: 954.14 toks/s, out\n",
      "[2025-07-09 01:34:01,769] [INFO] [distiller.distillation] - Final best prompt score on validation: 1.0\n",
      "[2025-07-09 01:34:01,769] [INFO] [distiller.distillation] - DistillPrompt optimization completed\n",
      "[2025-07-09 01:34:01,770] [INFO] [assistant.run] - Evaluating on given dataset for classification task...\n",
      "[2025-07-09 01:34:01,770] [INFO] [evaluator.evaluate] - Evaluating prompt for classification task on 10 samples\n",
      "Processed prompts: 100%|█| 10/10 [01:52<00:00, 11.22s/it, est. speed input: 4.22 toks/s, out\n",
      "[2025-07-09 01:35:53,981] [INFO] [evaluator.evaluate] - Evaluating prompt for classification task on 10 samples\n",
      "Processed prompts: 100%|█| 10/10 [00:00<00:00, 25.63it/s, est. speed input: 2288.73 toks/s, \n",
      "[2025-07-09 01:35:54,393] [INFO] [assistant.run] - Initial f1 score: 0.23076923076923078, final f1 score: 1.0\n",
      "[2025-07-09 01:35:54,393] [INFO] [assistant.run] - === Prompt Optimization Completed ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start prompt: Classify sentence sentiment\n",
      "Final prompt: Classify the sentiment of a sentence as positive, negative, or neutral.\n",
      "Examples:\n",
      "- \"I love this movie!\" is positive.\n",
      "- \"This movie is terrible.\" is negative.\n",
      "- \"The movie was okay.\" is neutral.\n",
      "Start prompt metric:  0.23076923076923078\n",
      "Final prompt metric:  1.0\n"
     ]
    }
   ],
   "source": [
    "tuner.run(\n",
    "    start_prompt=class_start_prompt,\n",
    "    task=\"classification\",\n",
    "    dataset=class_dataset[:10],\n",
    "    target=class_targets[:10],\n",
    "    method=\"distill\",\n",
    "    use_cache=False,\n",
    "    num_epochs=1\n",
    ")\n",
    "\n",
    "print_results(tuner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f677f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-07-09 01:35:54,509] [INFO] [assistant.run] - Validating args for PromptTuner running\n",
      "[2025-07-09 01:35:55,246] [INFO] [evaluator.__init__] - Evaluator sucessfully initialized with f1 metric\n",
      "[2025-07-09 01:35:55,246] [INFO] [assistant.run] - === Starting Prompt Optimization ===\n",
      "[2025-07-09 01:35:55,247] [INFO] [assistant.run] - Method: reflective, Task: classification\n",
      "[2025-07-09 01:35:55,247] [INFO] [assistant.run] - Metric: f1, Validation size: 0.25\n",
      "[2025-07-09 01:35:55,248] [INFO] [assistant.run] - Dataset: 10 samples\n",
      "[2025-07-09 01:35:55,248] [INFO] [assistant.run] - Target: 10 samples\n",
      "[2025-07-09 01:35:55,249] [INFO] [run.reflectiveprompt] - Starting ReflectivePrompt optimization...\n",
      "[2025-07-09 01:35:55,250] [INFO] [evoluter._init_pop] - Initializing population...\n",
      "Processed prompts: 100%|█| 1/1 [00:01<00:00,  1.78s/it, est. speed input: 44.52 toks/s, outp\n",
      "[2025-07-09 01:35:57,029] [INFO] [evoluter._evaluation] - Evaluating population...\n",
      "[2025-07-09 01:35:57,030] [INFO] [evaluator.evaluate] - Evaluating prompt for classification task on 7 samples\n",
      "Processed prompts: 100%|█| 7/7 [01:44<00:00, 14.92s/it, est. speed input: 3.45 toks/s, outpu\n",
      "[2025-07-09 01:37:41,464] [INFO] [evaluator.evaluate] - Evaluating prompt for classification task on 7 samples\n",
      "Processed prompts: 100%|█| 7/7 [01:49<00:00, 15.63s/it, est. speed input: 3.35 toks/s, outpu\n",
      "[2025-07-09 01:39:30,900] [INFO] [evaluator.evaluate] - Evaluating prompt for classification task on 7 samples\n",
      "Processed prompts: 100%|█| 7/7 [01:49<00:00, 15.63s/it, est. speed input: 3.35 toks/s, outpu\n",
      "[2025-07-09 01:41:20,349] [INFO] [evaluator.evaluate] - Evaluating prompt for classification task on 7 samples\n",
      "Processed prompts:  71%|▋| 5/7 [00:08<00:03,  1.64s/it, est. speed input: 29.21 toks/s, outp"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtuner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstart_prompt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclass_start_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mclassification\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclass_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclass_targets\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreflective\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproblem_description\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msentiment classification\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpopulation_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\n\u001b[32m     11\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m print_results(tuner)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/tank/scratch/asitkina/CoolPrompt/coolprompt/assistant.py:191\u001b[39m, in \u001b[36mPromptTuner.run\u001b[39m\u001b[34m(self, start_prompt, task, dataset, target, method, metric, problem_description, validation_size, verbose, **kwargs)\u001b[39m\n\u001b[32m    187\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m Method.REFLECTIVE:\n\u001b[32m    188\u001b[39m     dataset_split = train_test_split(\n\u001b[32m    189\u001b[39m         dataset, target, test_size=validation_size\n\u001b[32m    190\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m     final_prompt = \u001b[43mreflectiveprompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdataset_split\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m        \u001b[49m\u001b[43mevaluator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevaluator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproblem_description\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproblem_description\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[43m        \u001b[49m\u001b[43minitial_prompt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstart_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m Method.DISTILL:\n\u001b[32m    200\u001b[39m     dataset_split = train_test_split(dataset, target, test_size=\u001b[32m0.25\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/tank/scratch/asitkina/CoolPrompt/coolprompt/optimizer/reflective_prompt/run.py:61\u001b[39m, in \u001b[36mreflectiveprompt\u001b[39m\u001b[34m(model, dataset_split, evaluator, problem_description, initial_prompt, **kwargs)\u001b[39m\n\u001b[32m     59\u001b[39m logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mStart prompt:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00minitial_prompt\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     60\u001b[39m logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mProblem description:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mproblem_description\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m final_prompt = \u001b[43mevoluter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevolution\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     62\u001b[39m logger.info(\u001b[33m\"\u001b[39m\u001b[33mReflectivePrompt optimization completed\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m final_prompt\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/tank/scratch/asitkina/CoolPrompt/coolprompt/optimizer/reflective_prompt/evoluter.py:506\u001b[39m, in \u001b[36mReflectiveEvoluter.evolution\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    491\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mevolution\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m    492\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Provides evolution operation.\u001b[39;00m\n\u001b[32m    493\u001b[39m \n\u001b[32m    494\u001b[39m \u001b[33;03m    Selection -> Short-term reflection -> Long-term reflection\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    503\u001b[39m \u001b[33;03m        str: best evoluted prompt\u001b[39;00m\n\u001b[32m    504\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m506\u001b[39m     population = np.array(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_init_pop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    507\u001b[39m     \u001b[38;5;28mself\u001b[39m._cache_population(\n\u001b[32m    508\u001b[39m         population, \u001b[38;5;28mself\u001b[39m._make_output_path(\u001b[33m\"\u001b[39m\u001b[33minitial_population.yaml\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    509\u001b[39m     )\n\u001b[32m    511\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iteration < \u001b[38;5;28mself\u001b[39m.num_epochs:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/tank/scratch/asitkina/CoolPrompt/coolprompt/optimizer/reflective_prompt/evoluter.py:186\u001b[39m, in \u001b[36mReflectiveEvoluter._init_pop\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    182\u001b[39m prompts = json.loads(answer)[\u001b[33m\"\u001b[39m\u001b[33mprompts\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    183\u001b[39m initial_population = [\n\u001b[32m    184\u001b[39m     Prompt(prompt, origin=PromptOrigin.APE) \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m prompts\n\u001b[32m    185\u001b[39m ]\n\u001b[32m--> \u001b[39m\u001b[32m186\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_evaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_population\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    187\u001b[39m initial_population = \u001b[38;5;28mself\u001b[39m._reranking(initial_population)\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m initial_population\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/tank/scratch/asitkina/CoolPrompt/coolprompt/optimizer/reflective_prompt/evoluter.py:152\u001b[39m, in \u001b[36mReflectiveEvoluter._evaluation\u001b[39m\u001b[34m(self, population, split)\u001b[39m\n\u001b[32m    150\u001b[39m logger.info(\u001b[33m\"\u001b[39m\u001b[33mEvaluating population...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m population:\n\u001b[32m--> \u001b[39m\u001b[32m152\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[43m=\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/tank/scratch/asitkina/CoolPrompt/coolprompt/optimizer/reflective_prompt/evoluter.py:132\u001b[39m, in \u001b[36mReflectiveEvoluter._evaluate\u001b[39m\u001b[34m(self, prompt, split)\u001b[39m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    131\u001b[39m     dataset, targets = \u001b[38;5;28mself\u001b[39m.validation_dataset, \u001b[38;5;28mself\u001b[39m.validation_targets\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m score = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mevaluator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    137\u001b[39m prompt.set_score(score)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/tank/scratch/asitkina/CoolPrompt/coolprompt/evaluator/evaluator.py:70\u001b[39m, in \u001b[36mEvaluator.evaluate\u001b[39m\u001b[34m(self, prompt, dataset, targets, template)\u001b[39m\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.task == Task.CLASSIFICATION:\n\u001b[32m     68\u001b[39m     \u001b[38;5;28mself\u001b[39m.metric.extract_labels(targets)\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m answers = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_full_prompt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemplate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.metric.compute(answers, targets)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/langchain_core/language_models/llms.py:440\u001b[39m, in \u001b[36mBaseLLM.batch\u001b[39m\u001b[34m(self, inputs, config, return_exceptions, **kwargs)\u001b[39m\n\u001b[32m    438\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m max_concurrency \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    439\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m440\u001b[39m         llm_result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    441\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    442\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    443\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    444\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    445\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    446\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    447\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    448\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m [g[\u001b[32m0\u001b[39m].text \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m llm_result.generations]\n\u001b[32m    449\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/langchain_core/language_models/llms.py:764\u001b[39m, in \u001b[36mBaseLLM.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    755\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    756\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    757\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    761\u001b[39m     **kwargs: Any,\n\u001b[32m    762\u001b[39m ) -> LLMResult:\n\u001b[32m    763\u001b[39m     prompt_strings = [p.to_string() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m764\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_strings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/langchain_core/language_models/llms.py:971\u001b[39m, in \u001b[36mBaseLLM.generate\u001b[39m\u001b[34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    956\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m get_llm_cache() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m    957\u001b[39m     run_managers = [\n\u001b[32m    958\u001b[39m         callback_manager.on_llm_start(\n\u001b[32m    959\u001b[39m             \u001b[38;5;28mself\u001b[39m._serialized,\n\u001b[32m   (...)\u001b[39m\u001b[32m    969\u001b[39m         )\n\u001b[32m    970\u001b[39m     ]\n\u001b[32m--> \u001b[39m\u001b[32m971\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    976\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    978\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) > \u001b[32m0\u001b[39m:\n\u001b[32m    979\u001b[39m     run_managers = [\n\u001b[32m    980\u001b[39m         callback_managers[idx].on_llm_start(\n\u001b[32m    981\u001b[39m             \u001b[38;5;28mself\u001b[39m._serialized,\n\u001b[32m   (...)\u001b[39m\u001b[32m    988\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m missing_prompt_idxs\n\u001b[32m    989\u001b[39m     ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/langchain_core/language_models/llms.py:790\u001b[39m, in \u001b[36mBaseLLM._generate_helper\u001b[39m\u001b[34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[39m\n\u001b[32m    779\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_generate_helper\u001b[39m(\n\u001b[32m    780\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    781\u001b[39m     prompts: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m    786\u001b[39m     **kwargs: Any,\n\u001b[32m    787\u001b[39m ) -> LLMResult:\n\u001b[32m    788\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    789\u001b[39m         output = (\n\u001b[32m--> \u001b[39m\u001b[32m790\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m                \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[32m    794\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    797\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[32m    798\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._generate(prompts, stop=stop)\n\u001b[32m    799\u001b[39m         )\n\u001b[32m    800\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    801\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/langchain_community/llms/vllm.py:145\u001b[39m, in \u001b[36mVLLM._generate\u001b[39m\u001b[34m(self, prompts, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    141\u001b[39m     outputs = \u001b[38;5;28mself\u001b[39m.client.generate(\n\u001b[32m    142\u001b[39m         prompts, sample_params, lora_request=lora_request\n\u001b[32m    143\u001b[39m     )\n\u001b[32m    144\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    147\u001b[39m generations = []\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m outputs:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/vllm/utils.py:1057\u001b[39m, in \u001b[36mdeprecate_kwargs.<locals>.wrapper.<locals>.inner\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1050\u001b[39m             msg += \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00madditional_message\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1052\u001b[39m         warnings.warn(\n\u001b[32m   1053\u001b[39m             \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m(msg),\n\u001b[32m   1054\u001b[39m             stacklevel=\u001b[32m3\u001b[39m,  \u001b[38;5;66;03m# The inner function takes up one level\u001b[39;00m\n\u001b[32m   1055\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1057\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/vllm/entrypoints/llm.py:469\u001b[39m, in \u001b[36mLLM.generate\u001b[39m\u001b[34m(self, prompts, sampling_params, prompt_token_ids, use_tqdm, lora_request, prompt_adapter_request, guided_options_request, priority)\u001b[39m\n\u001b[32m    459\u001b[39m     sampling_params = \u001b[38;5;28mself\u001b[39m.get_default_sampling_params()\n\u001b[32m    461\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_and_add_requests(\n\u001b[32m    462\u001b[39m     prompts=parsed_prompts,\n\u001b[32m    463\u001b[39m     params=sampling_params,\n\u001b[32m   (...)\u001b[39m\u001b[32m    466\u001b[39m     guided_options=guided_options_request,\n\u001b[32m    467\u001b[39m     priority=priority)\n\u001b[32m--> \u001b[39m\u001b[32m469\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43muse_tqdm\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_tqdm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    470\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.engine_class.validate_outputs(outputs, RequestOutput)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/vllm/entrypoints/llm.py:1397\u001b[39m, in \u001b[36mLLM._run_engine\u001b[39m\u001b[34m(self, use_tqdm)\u001b[39m\n\u001b[32m   1395\u001b[39m total_out_toks = \u001b[32m0\u001b[39m\n\u001b[32m   1396\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m.llm_engine.has_unfinished_requests():\n\u001b[32m-> \u001b[39m\u001b[32m1397\u001b[39m     step_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mllm_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1398\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m step_outputs:\n\u001b[32m   1399\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m output.finished:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/vllm/engine/llm_engine.py:1391\u001b[39m, in \u001b[36mLLMEngine.step\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1387\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m allow_async_output_proc:\n\u001b[32m   1388\u001b[39m     execute_model_req.async_callback = \u001b[38;5;28mself\u001b[39m.async_callbacks[\n\u001b[32m   1389\u001b[39m         virtual_engine]\n\u001b[32m-> \u001b[39m\u001b[32m1391\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_executor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1392\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexecute_model_req\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexecute_model_req\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1394\u001b[39m \u001b[38;5;66;03m# We need to do this here so that last step's sampled_token_ids can\u001b[39;00m\n\u001b[32m   1395\u001b[39m \u001b[38;5;66;03m# be passed to the next iteration for PP.\u001b[39;00m\n\u001b[32m   1396\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.scheduler_config.is_multi_step:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/vllm/executor/executor_base.py:139\u001b[39m, in \u001b[36mExecutorBase.execute_model\u001b[39m\u001b[34m(self, execute_model_req)\u001b[39m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexecute_model\u001b[39m(\n\u001b[32m    137\u001b[39m     \u001b[38;5;28mself\u001b[39m, execute_model_req: ExecuteModelRequest\n\u001b[32m    138\u001b[39m ) -> Optional[List[Union[SamplerOutput, PoolerOutput]]]:\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m     output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcollective_rpc\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mexecute_model\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m                                 \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecute_model_req\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    141\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/vllm/executor/uniproc_executor.py:56\u001b[39m, in \u001b[36mUniProcExecutor.collective_rpc\u001b[39m\u001b[34m(self, method, timeout, args, kwargs)\u001b[39m\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     55\u001b[39m     kwargs = {}\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m answer = \u001b[43mrun_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdriver_worker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m [answer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/vllm/utils.py:2196\u001b[39m, in \u001b[36mrun_method\u001b[39m\u001b[34m(obj, method, args, kwargs)\u001b[39m\n\u001b[32m   2194\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2195\u001b[39m     func = partial(method, obj)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2196\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/vllm/worker/worker_base.py:420\u001b[39m, in \u001b[36mLocalOrDistributedWorkerBase.execute_model\u001b[39m\u001b[34m(self, execute_model_req)\u001b[39m\n\u001b[32m    415\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.observability_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    416\u001b[39m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.observability_config.collect_model_execute_time):\n\u001b[32m    417\u001b[39m         orig_model_execute_time = intermediate_tensors.tensors.get(\n\u001b[32m    418\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmodel_execute_time\u001b[39m\u001b[33m\"\u001b[39m, torch.tensor(\u001b[32m0\u001b[39m)).item()\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_runner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_input\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    422\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkv_caches\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkv_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mworker_input\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvirtual_engine\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    423\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkv_cache\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    424\u001b[39m \u001b[43m    \u001b[49m\u001b[43mintermediate_tensors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mintermediate_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    425\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    426\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    427\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    429\u001b[39m model_execute_time = time.perf_counter() - start_time\n\u001b[32m    430\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m get_pp_group().is_last_rank:\n\u001b[32m    431\u001b[39m     \u001b[38;5;66;03m# output is IntermediateTensors\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/vllm/worker/model_runner.py:1782\u001b[39m, in \u001b[36mModelRunner.execute_model\u001b[39m\u001b[34m(self, model_input, kv_caches, intermediate_tensors, num_steps, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m     model_input.async_callback()\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# Sample the next token.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1782\u001b[39m output: SamplerOutput = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1783\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1784\u001b[39m \u001b[43m    \u001b[49m\u001b[43msampling_metadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_input\u001b[49m\u001b[43m.\u001b[49m\u001b[43msampling_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1785\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.observability_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.observability_config.collect_model_forward_time\n\u001b[32m   1788\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   1789\u001b[39m     model_forward_end.synchronize()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py:505\u001b[39m, in \u001b[36mQwen2ForCausalLM.sample\u001b[39m\u001b[34m(self, logits, sampling_metadata)\u001b[39m\n\u001b[32m    500\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msample\u001b[39m(\n\u001b[32m    501\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    502\u001b[39m     logits: torch.Tensor,\n\u001b[32m    503\u001b[39m     sampling_metadata: SamplingMetadata,\n\u001b[32m    504\u001b[39m ) -> Optional[SamplerOutput]:\n\u001b[32m--> \u001b[39m\u001b[32m505\u001b[39m     next_tokens = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    506\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m next_tokens\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/vllm/model_executor/layers/sampler.py:287\u001b[39m, in \u001b[36mSampler.forward\u001b[39m\u001b[34m(self, logits, sampling_metadata)\u001b[39m\n\u001b[32m    284\u001b[39m logprobs = torch.log_softmax(logits, dim=-\u001b[32m1\u001b[39m, dtype=torch.float)\n\u001b[32m    286\u001b[39m \u001b[38;5;66;03m# Sample the next tokens.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m maybe_deferred_sample_results, maybe_sampled_tokens_tensor = \u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    288\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    289\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    290\u001b[39m \u001b[43m    \u001b[49m\u001b[43msampling_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    291\u001b[39m \u001b[43m    \u001b[49m\u001b[43msampling_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    292\u001b[39m \u001b[43m    \u001b[49m\u001b[43minclude_gpu_probs_tensor\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minclude_gpu_probs_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    293\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodify_greedy_probs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_should_modify_greedy_probs_inplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    294\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.include_gpu_probs_tensor:\n\u001b[32m    297\u001b[39m     \u001b[38;5;66;03m# Since we will defer sampler result Pythonization,\u001b[39;00m\n\u001b[32m    298\u001b[39m     \u001b[38;5;66;03m# preserve GPU-side tensors in support of later\u001b[39;00m\n\u001b[32m    299\u001b[39m     \u001b[38;5;66;03m# deferred pythonization of logprobs\u001b[39;00m\n\u001b[32m    300\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m maybe_sampled_tokens_tensor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/vllm/model_executor/layers/sampler.py:775\u001b[39m, in \u001b[36m_sample\u001b[39m\u001b[34m(probs, logprobs, sampling_metadata, sampling_tensors, include_gpu_probs_tensor, modify_greedy_probs)\u001b[39m\n\u001b[32m    755\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_sample\u001b[39m(\n\u001b[32m    756\u001b[39m     probs: torch.Tensor,\n\u001b[32m    757\u001b[39m     logprobs: torch.Tensor,\n\u001b[32m   (...)\u001b[39m\u001b[32m    761\u001b[39m     modify_greedy_probs: \u001b[38;5;28mbool\u001b[39m,\n\u001b[32m    762\u001b[39m ) -> SampleReturnType:\n\u001b[32m    763\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    764\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m    765\u001b[39m \u001b[33;03m        probs: (num_query_tokens_in_batch, num_vocab)\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    773\u001b[39m \u001b[33;03m        sampled_token_ids_tensor: A tensor of sampled token ids.\u001b[39;00m\n\u001b[32m    774\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_sample_with_torch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    776\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    777\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    778\u001b[39m \u001b[43m        \u001b[49m\u001b[43msampling_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    779\u001b[39m \u001b[43m        \u001b[49m\u001b[43msampling_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    780\u001b[39m \u001b[43m        \u001b[49m\u001b[43minclude_gpu_probs_tensor\u001b[49m\u001b[43m=\u001b[49m\u001b[43minclude_gpu_probs_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    781\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodify_greedy_probs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodify_greedy_probs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    782\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/vllm/model_executor/layers/sampler.py:744\u001b[39m, in \u001b[36m_sample_with_torch\u001b[39m\u001b[34m(probs, logprobs, sampling_metadata, sampling_tensors, include_gpu_probs_tensor, modify_greedy_probs)\u001b[39m\n\u001b[32m    733\u001b[39m maybe_deferred_args = SampleResultArgsType(\n\u001b[32m    734\u001b[39m     sampling_metadata=sampling_metadata,\n\u001b[32m    735\u001b[39m     sample_metadata=sample_metadata,\n\u001b[32m    736\u001b[39m     multinomial_samples=multinomial_samples,\n\u001b[32m    737\u001b[39m     greedy_samples=greedy_samples,\n\u001b[32m    738\u001b[39m     sample_results_dict=sample_results_dict)\n\u001b[32m    740\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sampling_metadata.skip_sampler_cpu_output:\n\u001b[32m    741\u001b[39m     \u001b[38;5;66;03m# GPU<->CPU sync happens here.\u001b[39;00m\n\u001b[32m    742\u001b[39m     \u001b[38;5;66;03m# This also converts the sampler output to a Python object.\u001b[39;00m\n\u001b[32m    743\u001b[39m     \u001b[38;5;66;03m# Return Pythonized sampler result & sampled token ids\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m744\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_pythonized_sample_results\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    745\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmaybe_deferred_args\u001b[49m\u001b[43m)\u001b[49m, sampled_token_ids_tensor\n\u001b[32m    746\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    747\u001b[39m     \u001b[38;5;66;03m# Defer sampler result Pythonization; return deferred\u001b[39;00m\n\u001b[32m    748\u001b[39m     \u001b[38;5;66;03m# Pythonization args & sampled token ids\u001b[39;00m\n\u001b[32m    749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m    750\u001b[39m         maybe_deferred_args,\n\u001b[32m    751\u001b[39m         sampled_token_ids_tensor,\n\u001b[32m    752\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/vllm/model_executor/layers/sampler.py:614\u001b[39m, in \u001b[36mget_pythonized_sample_results\u001b[39m\u001b[34m(sample_result_args)\u001b[39m\n\u001b[32m    612\u001b[39m (seq_group_id, seq_groups) = sample_metadata[sampling_type]\n\u001b[32m    613\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sampling_type == SamplingType.GREEDY:\n\u001b[32m--> \u001b[39m\u001b[32m614\u001b[39m     sample_results = \u001b[43m_greedy_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseq_groups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgreedy_samples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m sampling_type \u001b[38;5;129;01min\u001b[39;00m (SamplingType.RANDOM, SamplingType.RANDOM_SEED):\n\u001b[32m    616\u001b[39m     sample_results = _random_sample(seq_groups,\n\u001b[32m    617\u001b[39m                                     multinomial_samples[sampling_type])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/name/lib/python3.12/site-packages/vllm/model_executor/layers/sampler.py:449\u001b[39m, in \u001b[36m_greedy_sample\u001b[39m\u001b[34m(selected_seq_groups, samples)\u001b[39m\n\u001b[32m    433\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_greedy_sample\u001b[39m(\n\u001b[32m    434\u001b[39m     selected_seq_groups: List[SequenceGroupToSample],\n\u001b[32m    435\u001b[39m     samples: torch.Tensor,\n\u001b[32m    436\u001b[39m ) -> SampleResultType:\n\u001b[32m    437\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Run greedy sampling on a given samples.\u001b[39;00m\n\u001b[32m    438\u001b[39m \n\u001b[32m    439\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    447\u001b[39m \u001b[33;03m        seq_group has do_sample=False, tuple contains ([], [])\u001b[39;00m\n\u001b[32m    448\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     samples_lst = \u001b[43msamples\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    450\u001b[39m     sample_idx = \u001b[32m0\u001b[39m\n\u001b[32m    451\u001b[39m     results: SampleResultType = []\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "tuner.run(\n",
    "    start_prompt=class_start_prompt,\n",
    "    task=\"classification\",\n",
    "    dataset=class_dataset[:10],\n",
    "    target=class_targets[:10],\n",
    "    method=\"reflective\",\n",
    "    problem_description=\"sentiment classification\",\n",
    "    use_cache=False,\n",
    "    population_size=4,\n",
    "    num_epochs=1\n",
    ")\n",
    "\n",
    "print_results(tuner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97ebe58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
