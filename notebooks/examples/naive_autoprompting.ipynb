{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5c0b823",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"../../\"))\n",
    "sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "221f53d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracted prompts\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "prompts = [\n",
    "    \"What is common with the crow and writing table?\",\n",
    "    \"А как сделать чтобы langchain создал локальную модель\",\n",
    "    \"бро напиши пж решение задачи: доказать что моноид это категория\",\n",
    "    \"привет я составляю сборку для майнкрафт 1.21 neoforge и мне нужна база. это моды типа wawla, dynamic lights, jei+nei, journey миникарта, показ восстановления еды, показ прочности предметов, еще какие то\",\n",
    "    \"\"\">>> send_email(None)\n",
    "Traceback (most recent call last):\n",
    "  File \"<stdin>\", line 1, in <module>\n",
    "  File \"/path/to/project/main.py\", line 8, in send_email\n",
    "    raise InvalidEmailAddress(\"Invalid email address\")\n",
    "InvalidEmailAddress: Invalid email address\n",
    "а чо я неправильно пишу?\n",
    "\"\"\",\n",
    "]\n",
    "with open(\"../../data/basic_prompts.json\", \"r\") as f:\n",
    "    prompts_json = json.load(f)\n",
    "    for _, prompt in prompts_json.items():\n",
    "        if isinstance(prompt, str):\n",
    "            prompts.append(prompt)\n",
    "        else:\n",
    "            for _, p in prompt.items():\n",
    "                prompts.append(p)\n",
    "\n",
    "print(\"extracted prompts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "968dd629-4357-4929-9af9-ccf2a7023a75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What is common with the crow and writing table?',\n",
       " 'А как сделать чтобы langchain создал локальную модель',\n",
       " 'бро напиши пж решение задачи: доказать что моноид это категория',\n",
       " 'привет я составляю сборку для майнкрафт 1.21 neoforge и мне нужна база. это моды типа wawla, dynamic lights, jei+nei, journey миникарта, показ восстановления еды, показ прочности предметов, еще какие то',\n",
       " '>>> send_email(None)\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 1, in <module>\\n  File \"/path/to/project/main.py\", line 8, in send_email\\n    raise InvalidEmailAddress(\"Invalid email address\")\\nInvalidEmailAddress: Invalid email address\\nа чо я неправильно пишу?\\n',\n",
       " 'Evaluate the result of a random Boolean expression.',\n",
       " 'Order adjectives correctly in English sentences.',\n",
       " 'Answer questions about which times certain events could have occurred.',\n",
       " 'Questions that involve enumerating objects and asking the model to count them.',\n",
       " 'Clarify the meaning of sentences with ambiguous pronouns.',\n",
       " 'A logical deduction task which requires deducing the order of a sequence of objects.',\n",
       " 'A logical deduction task which requires deducing the order of a sequence of objects.',\n",
       " 'A logical deduction task which requires deducing the order of a sequence of objects.',\n",
       " 'Answer questions about causal attribution.',\n",
       " ' Infer the date from context.',\n",
       " \"Select the humorous edit that 'ruins' the input movie or musical artist name.\",\n",
       " 'Sort a list of words.',\n",
       " 'Name geometric shapes from their SVG paths.',\n",
       " 'Recommend movies similar to the given list of movies.',\n",
       " 'Detect the type of error in an English translation of a German source sentence.',\n",
       " 'Distinguish deductively valid arguments from formal fallacies.',\n",
       " 'Answer questions about a table of penguins and their attributes.',\n",
       " ' Correctly close a Dyck-n word.',\n",
       " 'Solve multi-step arithmetic problems.',\n",
       " 'Given a series of navigation instructions, determine whether one would end up back at the starting point.',\n",
       " 'Answer extremely simple questions about the colors of objects on a surface.',\n",
       " 'A task requiring determining the final positions of a set of objects given their initial positions and a description of a sequence of swaps.',\n",
       " 'A task requiring determining the final positions of a set of objects given their initial positions and a description of a sequence of swaps.',\n",
       " 'A task requiring determining the final positions of a set of objects given their initial positions and a description of a sequence of swaps.',\n",
       " 'Determine whether an artificially constructed sentence relating to sports is plausible or not.',\n",
       " 'Determine which of two sentences is sarcastic.',\n",
       " 'Evaluate the truth value of a random Boolean function expressed as a natural-language word problem.',\n",
       " 'Solve the math word problem, giving your answer as an arabic numeral.',\n",
       " 'Solve the math word problem',\n",
       " 'Please use your domain knowledge in medical area to solve the questions.',\n",
       " \"In this task, you're given a pair of sentences, premise and hypothesis. Your job is to choose whether the two sentences clearly agree/disagree with each other, or if this cannot be determined.\",\n",
       " 'Please perform Sentiment Classification task',\n",
       " \"A question that is free of any grammatical or logical errors, should be labeled 'Yes.', otherwise it should be indicated as 'No.'. A question is grammatically correct if all its entities i.e. nouns, verbs, adjectives, prepositions, pronouns, adverbs are at appropriate position. A question is logically correct if the semantic makes sense.\",\n",
       " 'You are given a sentence and a question in the input. If the information provided in the sentence is enough to answer the question, label \"Yes.\", otherwise label \"No.\". Do not use any facts other than those provided in the sentence while labeling \"Yes.\" or \"No.\".',\n",
       " 'In this task, you will be shown a short story with a beginning, two potential middles, and an ending. Your job is to choose the middle statement that makes the story coherent / plausible by writing \"1\" or \"2\" in the output. If both sentences are plausible, pick the one that makes most sense.',\n",
       " 'Answer the following question: ',\n",
       " 'Define if the sentence entails the question.',\n",
       " 'Summarize the following text',\n",
       " 'Please perform Sentiment Classification task.',\n",
       " 'Classify this sentence based on the provided categories.',\n",
       " 'Identify the most suitable category for this question.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "792dae57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-14 18:17:45 __init__.py:207] Automatically detected platform cuda.\n",
      "INFO 05-14 18:17:52 config.py:549] This model supports multiple tasks: {'embed', 'classify', 'score', 'generate', 'reward'}. Defaulting to 'generate'.\n",
      "INFO 05-14 18:17:52 config.py:1382] Defaulting to use mp for distributed inference\n",
      "INFO 05-14 18:17:52 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='t-tech/T-lite-it-1.0', speculative_config=None, tokenizer='t-tech/T-lite-it-1.0', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=1600, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=2, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=t-tech/T-lite-it-1.0, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"splitting_ops\":[],\"compile_sizes\":[],\"cudagraph_capture_sizes\":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":256}, use_cached_outputs=False, \n",
      "WARNING 05-14 18:17:53 multiproc_worker_utils.py:300] Reducing Torch parallelism from 10 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.\n",
      "INFO 05-14 18:17:53 custom_cache_manager.py:19] Setting Triton cache manager to: vllm.triton_utils.custom_cache_manager:CustomCacheManager\n",
      "\u001b[1;36m(VllmWorkerProcess pid=195699)\u001b[0;0m INFO 05-14 18:17:53 multiproc_worker_utils.py:229] Worker ready; awaiting tasks\n",
      "\u001b[1;36m(VllmWorkerProcess pid=195699)\u001b[0;0m INFO 05-14 18:17:54 cuda.py:229] Using Flash Attention backend.\n",
      "INFO 05-14 18:17:54 cuda.py:229] Using Flash Attention backend.\n",
      "INFO 05-14 18:17:54 utils.py:916] Found nccl from library libnccl.so.2\n",
      "INFO 05-14 18:17:54 pynccl.py:69] vLLM is using nccl==2.21.5\n",
      "\u001b[1;36m(VllmWorkerProcess pid=195699)\u001b[0;0m INFO 05-14 18:17:54 utils.py:916] Found nccl from library libnccl.so.2\n",
      "\u001b[1;36m(VllmWorkerProcess pid=195699)\u001b[0;0m INFO 05-14 18:17:54 pynccl.py:69] vLLM is using nccl==2.21.5\n",
      "INFO 05-14 18:17:55 custom_all_reduce_utils.py:244] reading GPU P2P access cache from /nfs/home/ahairulin/.cache/vllm/gpu_p2p_access_cache_for_0,1.json\n",
      "\u001b[1;36m(VllmWorkerProcess pid=195699)\u001b[0;0m INFO 05-14 18:17:55 custom_all_reduce_utils.py:244] reading GPU P2P access cache from /nfs/home/ahairulin/.cache/vllm/gpu_p2p_access_cache_for_0,1.json\n",
      "WARNING 05-14 18:17:55 custom_all_reduce.py:145] Custom allreduce is disabled because your platform lacks GPU P2P capability or P2P test failed. To silence this warning, specify disable_custom_all_reduce=True explicitly.\n",
      "\u001b[1;36m(VllmWorkerProcess pid=195699)\u001b[0;0m WARNING 05-14 18:17:55 custom_all_reduce.py:145] Custom allreduce is disabled because your platform lacks GPU P2P capability or P2P test failed. To silence this warning, specify disable_custom_all_reduce=True explicitly.\n",
      "INFO 05-14 18:17:55 shm_broadcast.py:258] vLLM message queue communication handle: Handle(connect_ip='127.0.0.1', local_reader_ranks=[1], buffer_handle=(1, 4194304, 6, 'psm_e4fd430b'), local_subscribe_port=35809, remote_subscribe_port=None)\n",
      "INFO 05-14 18:17:55 model_runner.py:1110] Starting to load model t-tech/T-lite-it-1.0...\n",
      "\u001b[1;36m(VllmWorkerProcess pid=195699)\u001b[0;0m INFO 05-14 18:17:55 model_runner.py:1110] Starting to load model t-tech/T-lite-it-1.0...\n",
      "\u001b[1;36m(VllmWorkerProcess pid=195699)\u001b[0;0m INFO 05-14 18:17:55 weight_utils.py:254] Using model weights format ['*.safetensors']\n",
      "INFO 05-14 18:17:55 weight_utils.py:254] Using model weights format ['*.safetensors']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc4621ec05b148f9aed875ea6b742e8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(VllmWorkerProcess pid=195699)\u001b[0;0m INFO 05-14 18:19:17 model_runner.py:1115] Loading model weights took 7.1186 GB\n",
      "INFO 05-14 18:19:17 model_runner.py:1115] Loading model weights took 7.1186 GB\n",
      "\u001b[1;36m(VllmWorkerProcess pid=195699)\u001b[0;0m INFO 05-14 18:19:22 worker.py:267] Memory profiling takes 4.73 seconds\n",
      "\u001b[1;36m(VllmWorkerProcess pid=195699)\u001b[0;0m INFO 05-14 18:19:22 worker.py:267] the current vLLM instance can use total_gpu_memory (11.76GiB) x gpu_memory_utilization (0.90) = 10.58GiB\n",
      "\u001b[1;36m(VllmWorkerProcess pid=195699)\u001b[0;0m INFO 05-14 18:19:22 worker.py:267] model weights take 7.12GiB; non_torch_memory takes 0.20GiB; PyTorch activation peak memory takes 0.19GiB; the rest of the memory reserved for KV Cache is 3.08GiB.\n",
      "INFO 05-14 18:19:22 worker.py:267] Memory profiling takes 4.88 seconds\n",
      "INFO 05-14 18:19:22 worker.py:267] the current vLLM instance can use total_gpu_memory (11.76GiB) x gpu_memory_utilization (0.90) = 10.58GiB\n",
      "INFO 05-14 18:19:22 worker.py:267] model weights take 7.12GiB; non_torch_memory takes 0.20GiB; PyTorch activation peak memory takes 1.40GiB; the rest of the memory reserved for KV Cache is 1.87GiB.\n",
      "INFO 05-14 18:19:22 executor_base.py:111] # cuda blocks: 4374, # CPU blocks: 9362\n",
      "INFO 05-14 18:19:22 executor_base.py:116] Maximum concurrency for 1600 tokens per request: 43.74x\n",
      "INFO 05-14 18:19:26 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "\u001b[1;36m(VllmWorkerProcess pid=195699)\u001b[0;0m INFO 05-14 18:19:26 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Capturing CUDA graph shapes: 100%|████████████████████████████████████████████████████████████████████████| 35/35 [00:20<00:00,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(VllmWorkerProcess pid=195699)\u001b[0;0m INFO 05-14 18:19:47 model_runner.py:1562] Graph capturing finished in 21 secs, took 0.42 GiB\n",
      "INFO 05-14 18:19:47 model_runner.py:1562] Graph capturing finished in 21 secs, took 0.42 GiB\n",
      "INFO 05-14 18:19:47 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 30.31 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from coolprompt.assistant import PromptTuner\n",
    "pt = PromptTuner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa563efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt: What is common with the crow and writing table?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████████████████████████| 1/1 [00:00<00:00,  1.92it/s, est. speed input: 111.44 toks/s, output: 44.19 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: larities between crows and writing tables, and can you provide an example to illustrate these similarities?\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "prompt: А как сделать чтобы langchain создал локальную модель\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████████████████████████████| 1/1 [00:19<00:00, 19.45s/it, est. speed input: 3.19 toks/s, output: 79.11 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: How can I rephrase the prompt to maximize its effectiveness for LLMs when creating a local model with LangChain, while ensuring clarity, removing ambiguity, and incorporating an example? \n",
      "\n",
      "Output:\n",
      "How can I rephrase the prompt to enhance its effectiveness for LLMs in creating a local model with LangChain, ensuring clarity, removing ambiguity, and adding an example? \n",
      "\n",
      "Rewritten prompt:\n",
      "How can I improve the prompt to better guide LLMs in creating a local model with LangChain, while ensuring clarity, removing ambiguity, and providing an example? \n",
      "\n",
      "Output:\n",
      "How can I structure the prompt to effectively guide LLMs in creating a local model with LangChain, ensuring clarity, removing ambiguity, and including an example? \n",
      "\n",
      "Rewritten prompt:\n",
      "How can I optimize the prompt for LLMs to create a local model with LangChain, ensuring clarity, removing ambiguity, and adding an example? \n",
      "\n",
      "Output:\n",
      "How can I optimize the prompt for LLMs to create a local model with LangChain, ensuring clarity, removing ambiguity, and providing an example? \n",
      "\n",
      "Rewritten prompt:\n",
      "How can I structure the prompt to effectively guide LLMs in creating a local model with LangChain, ensuring clarity, removing ambiguity, and including an example? \n",
      "\n",
      "Output:\n",
      "How can I rephrase the prompt to maximize its effectiveness for LLMs when creating a local model with LangChain, ensuring clarity, removing ambiguity, and adding an example? \n",
      "\n",
      "Rewritten prompt:\n",
      "How can I improve the clarity and effectiveness of the prompt for LLMs in creating a local model with LangChain, while ensuring clarity, removing ambiguity, and providing an example? \n",
      "\n",
      "Output:\n",
      "How can I rephrase the prompt to enhance its effectiveness for LLMs in creating a local model with LangChain, ensuring clarity, removing ambiguity, and adding an example? \n",
      "\n",
      "Rewritten prompt:\n",
      "How can I structure the prompt to effectively guide LLMs in creating a local model with LangChain, ensuring clarity, removing ambiguity, and including an example? \n",
      "\n",
      "Output:\n",
      "How can I rephrase the prompt to maximize its effectiveness for LLMs when creating a local model with LangChain, ensuring clarity, removing ambiguity, and adding an example? \n",
      "\n",
      "Rewritten prompt:\n",
      "How can I optimize the prompt for LLMs to create a local model with LangChain, ensuring clarity, removing ambiguity, and providing an example? \n",
      "\n",
      "Output:\n",
      "How can I rephrase the prompt to enhance its effectiveness for LLMs in creating a local model with LangChain, ensuring clarity, removing ambiguity, and adding an example? \n",
      "\n",
      "Rewritten prompt:\n",
      "How can I structure the prompt to effectively guide LLMs in creating a local model with LangChain, ensuring clarity, removing ambiguity, and including an example? \n",
      "\n",
      "Output:\n",
      "How can I rephrase the prompt to maximize its effectiveness for LLMs when creating a local model with LangChain, ensuring clarity, removing ambiguity, and adding an example? \n",
      "\n",
      "Rewritten prompt:\n",
      "How can I improve the clarity and effectiveness of the prompt for LLMs in creating a local model with LangChain, while ensuring clarity, removing ambiguity, and providing an example? \n",
      "\n",
      "Output:\n",
      "How can I rephrase the prompt to enhance its effectiveness for LLMs in creating a local model with LangChain, ensuring clarity, removing ambiguity, and adding an example? \n",
      "\n",
      "Rewritten prompt:\n",
      "How can I structure the prompt to effectively guide LLMs in creating a local model with LangChain, ensuring clarity, removing ambiguity, and including an example? \n",
      "\n",
      "Output:\n",
      "How can I rephrase the prompt to maximize its effectiveness for LLMs when creating a local model with LangChain, ensuring clarity, removing ambiguity, and adding an example? \n",
      "\n",
      "Rewritten prompt:\n",
      "How can I optimize the prompt for LLMs to create a local model with LangChain, ensuring clarity, removing ambiguity, and providing an example? \n",
      "\n",
      "Output:\n",
      "How can I rephrase the prompt to enhance its effectiveness for LLMs in creating a local model with LangChain, ensuring clarity, removing ambiguity, and adding an example? \n",
      "\n",
      "Rewritten prompt:\n",
      "How can I structure the prompt to effectively guide LLMs in creating a local model with LangChain, ensuring clarity, removing ambiguity, and including an example? \n",
      "\n",
      "Output:\n",
      "How can I rephrase the prompt to maximize its effectiveness for LLMs when creating a local model with LangChain, ensuring clarity, removing ambiguity, and adding an example? \n",
      "\n",
      "Rewritten prompt:\n",
      "How can I optimize the prompt for LLMs to create a local model with LangChain, ensuring clarity, removing ambiguity, and providing an example? \n",
      "\n",
      "Output:\n",
      "How can I rephrase the prompt to enhance its effectiveness for LLMs in creating a local model with LangChain, ensuring clarity, removing ambiguity, and adding an example? \n",
      "\n",
      "Rewritten prompt:\n",
      "How can I structure the prompt to effectively guide LLMs in creating a local model with LangChain, ensuring clarity, removing ambiguity, and including an example? \n",
      "\n",
      "Output:\n",
      "How can I rephrase the prompt to maximize its effectiveness for LLMs when creating a local model with LangChain, ensuring clarity, removing ambiguity, and adding an example? \n",
      "\n",
      "Rewritten prompt:\n",
      "How can I optimize the prompt for LLMs to create a local model with LangChain, ensuring clarity, removing ambiguity, and providing an example? \n",
      "\n",
      "Output:\n",
      "How can I rephrase the prompt to enhance its effectiveness for LLMs in creating a local model with LangChain, ensuring clarity, removing ambiguity, and adding an example? \n",
      "\n",
      "Rewritten prompt:\n",
      "How can I structure the prompt to effectively guide LLMs in creating a local model with LangChain, ensuring clarity, removing ambiguity, and including an example? \n",
      "\n",
      "Output:\n",
      "How can I rephrase the prompt to maximize its effectiveness for LLMs when creating a local model with LangChain, ensuring clarity, removing ambiguity, and adding an example? \n",
      "\n",
      "Rewritten prompt:\n",
      "How can I optimize the prompt for LLMs to create a local model with LangChain, ensuring clarity, removing ambiguity, and providing an example? \n",
      "\n",
      "Output:\n",
      "How can I rephrase the prompt to enhance its effectiveness for LLMs in creating a local model with LangChain, ensuring clarity, removing ambiguity, and adding an example? \n",
      "\n",
      "Rewritten prompt:\n",
      "How can I structure the prompt to effectively guide LLMs in creating a local model with LangChain, ensuring clarity, removing ambiguity, and including an example? \n",
      "\n",
      "Output:\n",
      "How can I rephrase the prompt to maximize its effectiveness for LLMs when creating a local model with LangChain, ensuring clarity, removing ambiguity, and adding an example? \n",
      "\n",
      "Rewritten prompt:\n",
      "How can I optimize the prompt for LLMs to create a local model with LangChain, ensuring clarity, removing ambiguity, and providing an example? \n",
      "\n",
      "Output:\n",
      "How can I rephrase the prompt to enhance its effectiveness for LLMs in creating a local model with LangChain, ensuring clarity, removing ambiguity, and adding an example? \n",
      "\n",
      "Rewritten prompt:\n",
      "How can I structure the prompt to effectively guide LLMs in creating a local model with LangChain, ensuring clarity, removing ambiguity, and including an example? \n",
      "\n",
      "Output:\n",
      "How can I rephrase the prompt to maximize its\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "prompt: бро напиши пж решение задачи: доказать что моноид это категория\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████████████████████████| 1/1 [00:02<00:00,  2.96s/it, est. speed input: 23.29 toks/s, output: 79.31 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: Rephrase the problem statement to clarify the intent: \"Prove that a monoid, which is a set equipped with an associative binary operation and an identity element, can be considered a category with a single object, where the morphisms are the elements of the monoid, and composition of morphisms is given by the monoid operation.\" Add an example to illustrate the concept. \"Consider a monoid (M, *) with elements {a, b, c} and operation * defined as follows: a * a = a, a * b = b, a * c = c, b * a = b, b * b = b, b * c = c, c * a = c, c * b = c, c * c = c. Show how this monoid can be represented as a category with a single object and morphisms corresponding to the elements of the monoid, and explain how composition of morphisms aligns with the monoid operation.\"\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "prompt: привет я составляю сборку для майнкрафт 1.21 neoforge и мне нужна база. это моды типа wawla, dynamic lights, jei+nei, journey миникарта, показ восстановления еды, показ прочности предметов, еще какие то\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████████████████████████| 1/1 [00:00<00:00,  1.15it/s, est. speed input: 135.12 toks/s, output: 75.07 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: bling a Minecraft 1.21 Neoforge modpack and need a base. Can you provide a structured list of specific mods like WAWLA, Dynamic Lights, JEI+NEI, Journey Minimap, Food Restoration display, Item Durability display, and any additional relevant mods?\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "prompt: >>> send_email(None)\n",
      "Traceback (most recent call last):\n",
      "  File \"<stdin>\", line 1, in <module>\n",
      "  File \"/path/to/project/main.py\", line 8, in send_email\n",
      "    raise InvalidEmailAddress(\"Invalid email address\")\n",
      "InvalidEmailAddress: Invalid email address\n",
      "а чо я неправильно пишу?\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████████████████████████| 1/1 [00:01<00:00,  1.77s/it, est. speed input: 66.79 toks/s, output: 77.55 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: ne)\n",
      "Traceback (most recent call last):\n",
      "  File \"<stdin>\", line 1, in <module>\n",
      "  File \"/path/to/project/main.py\", line 8, in send_email\n",
      "    raise InvalidEmailAddress(\"Invalid email address\")\n",
      "InvalidEmailAddress: Invalid email address\n",
      "\n",
      "Please provide a clear and concise explanation of the error, including specific examples, and suggest a corrected code snippet to fix the issue. For example, if the error is related to an invalid email address, provide an example of a valid email address and explain why the current input is invalid. Additionally, provide a corrected code snippet that demonstrates the proper usage of the `send_email` function.\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "prompt: Evaluate the result of a random Boolean expression.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████████████████████████| 1/1 [00:00<00:00,  2.55it/s, est. speed input: 145.72 toks/s, output: 74.14 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: lowing Boolean expression into a structured format, providing specific details, removing any ambiguity, and including an example to illustrate the intended outcome.\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "prompt: Order adjectives correctly in English sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████████████████████████| 1/1 [00:00<00:00,  2.73it/s, est. speed input: 152.77 toks/s, output: 73.65 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: re and arrange adjectives in English sentences, providing specific examples to clarify their order and ensuring clarity by removing any ambiguity.\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "prompt: Answer questions about which times certain events could have occurred.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.33it/s, est. speed input: 255.88 toks/s, output: 69.39 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result:  timeframes for specific events, providing examples to clarify ambiguity.\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "prompt: Questions that involve enumerating objects and asking the model to count them.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████████████████████████| 1/1 [00:00<00:00,  1.78it/s, est. speed input: 110.72 toks/s, output: 75.00 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: mpt by structuring it, providing specifics, removing ambiguity, adding an example, and preserving the original intent: \"Count the number of objects in the following list: [example list of objects].\"\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "prompt: Clarify the meaning of sentences with ambiguous pronouns.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████████████████████████| 1/1 [00:00<00:00,  3.12it/s, est. speed input: 184.31 toks/s, output: 71.85 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result:  with ambiguous pronouns by providing clear antecedents and adding examples to maintain the original intent.\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "prompt: A logical deduction task which requires deducing the order of a sequence of objects.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████████████████████████| 1/1 [00:00<00:00,  2.93it/s, est. speed input: 187.61 toks/s, output: 73.28 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: ce order of objects through logical reasoning, providing a structured explanation with specific examples to clarify any ambiguity.\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "prompt: A logical deduction task which requires deducing the order of a sequence of objects.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████████████████████████| 1/1 [00:00<00:00,  1.83it/s, est. speed input: 117.22 toks/s, output: 75.09 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: of a sequence of objects using logical reasoning. Provide a clear and concise explanation of your deduction process, and include an example of how to apply this reasoning to a specific sequence.\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "prompt: A logical deduction task which requires deducing the order of a sequence of objects.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████████████████████████| 1/1 [00:00<00:00,  1.95it/s, est. speed input: 125.13 toks/s, output: 74.29 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: ical deduction task by structuring it, providing specific examples, removing ambiguity, and adding context to deduce the order of a sequence of objects. Keep the original intent intact.\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "prompt: Answer questions about causal attribution.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████████████████████████| 1/1 [00:00<00:00,  1.25it/s, est. speed input: 67.33 toks/s, output: 76.06 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: ions: structure, specifics, remove ambiguity, add example, keep intent. Answer questions about causal attribution. For example, \"What factors led to the increase in sales last quarter?\" or \"How did the new marketing campaign affect customer satisfaction?\" Provide detailed explanations and examples to clarify the causal relationships.\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "prompt:  Infer the date from context.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████████████████████████| 1/1 [00:01<00:00,  1.01s/it, est. speed input: 53.72 toks/s, output: 76.61 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: mpt by structuring it, adding specifics, removing ambiguity, and providing an example while keeping the original intent. \n",
      "\n",
      "Revised prompt:\n",
      "Given a context, infer the date. For example, if the context is \"The Fourth of July\", the inferred date is July 4th, 2023 (assuming the current year is 2023).\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "prompt: Select the humorous edit that 'ruins' the input movie or musical artist name.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████████████████████████| 1/1 [00:00<00:00,  3.61it/s, est. speed input: 234.89 toks/s, output: 68.66 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: iest alteration that 'spoils' the original movie or artist name.\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "prompt: Sort a list of words.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.31it/s, est. speed input: 233.36 toks/s, output: 69.14 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: f words alphabetically, providing an example for clarity.\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "prompt: Name geometric shapes from their SVG paths.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████████████████████████| 1/1 [00:00<00:00,  3.89it/s, est. speed input: 217.98 toks/s, output: 70.06 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: c shapes by analyzing their SVG path data and provide examples for each shape.\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "prompt: Recommend movies similar to the given list of movies.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████████████████████████| 1/1 [00:00<00:00,  3.25it/s, est. speed input: 188.59 toks/s, output: 71.53 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: with similar themes and styles to the given list of movies, providing specific examples for each recommendation.\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "prompt: Detect the type of error in an English translation of a German source sentence.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████████████████████████| 1/1 [00:00<00:00,  2.12it/s, est. speed input: 133.76 toks/s, output: 74.31 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: r type in the English translation of a German source sentence by applying transformations such as restructuring, providing specific examples, removing ambiguity, and maintaining the original intent.\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "prompt: Distinguish deductively valid arguments from formal fallacies.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████████████████████████| 1/1 [00:00<00:00,  2.60it/s, est. speed input: 153.49 toks/s, output: 72.84 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: ely valid arguments and formal fallacies by structuring them, providing specific examples, removing ambiguity, and clarifying intent.\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "prompt: Answer questions about a table of penguins and their attributes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████████████████████████| 1/1 [00:00<00:00,  3.23it/s, est. speed input: 194.28 toks/s, output: 71.23 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: uestions about the attributes of penguins in a table, providing clear examples and removing any ambiguity.\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "prompt:  Correctly close a Dyck-n word.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████████████████████████| 1/1 [00:01<00:00,  1.02s/it, est. speed input: 55.93 toks/s, output: 76.53 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: rrectly close a Dyck-n word\" prompt by structuring it, adding specifics, removing ambiguity, providing an example, and keeping the intent. Output the revised prompt: \"Given a Dyck-n word, identify the correct sequence of closing parentheses to ensure the word is balanced, and provide an example of a Dyck-3 word with its corresponding closing sequence.\"\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "prompt: Solve multi-step arithmetic problems.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████████████████████████| 1/1 [00:00<00:00,  1.45it/s, est. speed input: 80.05 toks/s, output: 75.68 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: arithmetic problems by applying transformations: structure, specifics, remove ambiguity, add example, and keep intent. Provide a detailed solution for the following problem: 45 + 27 - 19 * 3 / 6.\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "prompt: Given a series of navigation instructions, determine whether one would end up back at the starting point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████████████████████████| 1/1 [00:00<00:00,  2.84it/s, est. speed input: 190.35 toks/s, output: 71.02 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: of navigation instructions, assess if following them would return to the initial location. Provide an example for clarity.\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "prompt: Answer extremely simple questions about the colors of objects on a surface.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████████████████████████| 1/1 [00:00<00:00,  3.52it/s, est. speed input: 215.12 toks/s, output: 70.53 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: stions about the colors of objects on a surface, providing specific examples and avoiding ambiguity.\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "prompt: A task requiring determining the final positions of a set of objects given their initial positions and a description of a sequence of swaps.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████████████████████████| 1/1 [00:00<00:00,  2.08it/s, est. speed input: 152.07 toks/s, output: 72.91 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: al positions of a set of objects after applying a sequence of swaps, given their initial positions and a description of the swaps. Provide an example for clarity.\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "prompt: A task requiring determining the final positions of a set of objects given their initial positions and a description of a sequence of swaps.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████████████████████████| 1/1 [00:00<00:00,  1.23it/s, est. speed input: 90.08 toks/s, output: 75.27 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: k by structuring it as follows: Given a set of objects with initial positions and a sequence of swaps, determine their final positions. Include specifics like object labels and swap details. Remove any ambiguity in the description. Provide an example of the input and output format. Maintain the original intent.\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "prompt: A task requiring determining the final positions of a set of objects given their initial positions and a description of a sequence of swaps.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████████████████████████| 1/1 [00:00<00:00,  2.03it/s, est. speed input: 148.09 toks/s, output: 73.03 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: f identifying the final positions of a set of objects, starting from their initial positions, after executing a specified sequence of swaps. Provide an example for clarity.\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "prompt: Determine whether an artificially constructed sentence relating to sports is plausible or not.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████████████████████████| 1/1 [00:00<00:00,  2.23it/s, est. speed input: 140.36 toks/s, output: 73.52 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: sibility of a sports-related sentence created artificially, considering structure, specific details, removing ambiguity, and providing an example to maintain the original intent.\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "prompt: Determine which of two sentences is sarcastic.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████████████████████████| 1/1 [00:00<00:00,  2.88it/s, est. speed input: 167.46 toks/s, output: 72.18 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: astic sentence by transforming it into a clear, specific format with an example, and remove any ambiguity.\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "prompt: Evaluate the truth value of a random Boolean function expressed as a natural-language word problem.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████████████████████████| 1/1 [00:00<00:00,  2.33it/s, est. speed input: 151.77 toks/s, output: 72.38 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: en natural-language word problem into a structured Boolean function, providing specific details, eliminating any ambiguity, and adding an example to clarify the intent.\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "prompt: Solve the math word problem, giving your answer as an arabic numeral.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████████████████████████| 1/1 [00:00<00:00,  2.16it/s, est. speed input: 138.56 toks/s, output: 73.61 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: rd problem and provide the answer as a single arabic numeral, ensuring clarity and removing any ambiguity. Include a clear example to illustrate your solution.\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "prompt: Solve the math word problem\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████████████████████████| 1/1 [00:00<00:00,  3.00it/s, est. speed input: 165.08 toks/s, output: 72.03 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: h word problem into a clear, specific, unambiguous question with an example, maintaining the original intent.\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "prompt: Please use your domain knowledge in medical area to solve the questions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████████████████████████| 1/1 [00:00<00:00,  2.43it/s, est. speed input: 148.56 toks/s, output: 73.06 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: cal expertise to address the questions by applying transformations: structure, specifics, remove ambiguity, add example, and maintain the original intent.\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "prompt: In this task, you're given a pair of sentences, premise and hypothesis. Your job is to choose whether the two sentences clearly agree/disagree with each other, or if this cannot be determined.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████████████████████████| 1/1 [00:00<00:00,  2.45it/s, est. speed input: 216.19 toks/s, output: 71.24 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: nd a hypothesis, determine if they clearly agree, disagree, or if it's unclear. Provide an example for each scenario.\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "prompt: Please perform Sentiment Classification task\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████████████████████████| 1/1 [00:00<00:00,  2.01it/s, est. speed input: 110.46 toks/s, output: 74.31 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result:  Classification by analyzing the sentiment of a given text, providing a clear classification as positive, negative, or neutral. Example: \"I love this product!\" is positive.\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "prompt: A question that is free of any grammatical or logical errors, should be labeled 'Yes.', otherwise it should be indicated as 'No.'. A question is grammatically correct if all its entities i.e. nouns, verbs, adjectives, prepositions, pronouns, adverbs are at appropriate position. A question is logically correct if the semantic makes sense.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████████████████████████| 1/1 [00:00<00:00,  1.36it/s, est. speed input: 163.85 toks/s, output: 73.73 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: d 'Yes.' if free of grammatical and logical errors, 'No.' otherwise. Ensure correct entity positions: nouns, verbs, adjectives, prepositions, pronouns, adverbs. Semantic coherence is required for logical correctness. Provide an example.\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "prompt: You are given a sentence and a question in the input. If the information provided in the sentence is enough to answer the question, label \"Yes.\", otherwise label \"No.\". Do not use any facts other than those provided in the sentence while labeling \"Yes.\" or \"No.\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████████████████████████| 1/1 [00:01<00:00,  1.03s/it, est. speed input: 101.95 toks/s, output: 75.74 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: and a question, determine if the sentence provides sufficient information to answer the question. If so, label \"Yes.\"; otherwise, label \"No.\". Utilize only the information provided in the sentence for labeling, and do not incorporate external knowledge. Example: Sentence: \"The cat is on the mat.\" Question: \"Is the cat indoors?\" Label: \"Yes.\"\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "prompt: In this task, you will be shown a short story with a beginning, two potential middles, and an ending. Your job is to choose the middle statement that makes the story coherent / plausible by writing \"1\" or \"2\" in the output. If both sentences are plausible, pick the one that makes most sense.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████████████████████████| 1/1 [00:00<00:00,  1.05it/s, est. speed input: 119.65 toks/s, output: 75.57 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result:  will be given a short story with a beginning, two potential middles, and an ending. Your goal is to select the middle statement that creates a coherent and plausible narrative by writing \"1\" or \"2\" in the output. If both sentences are plausible, choose the one that best aligns with the story's intent.\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "prompt: Answer the following question: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████████████████████████| 1/1 [00:00<00:00,  2.98it/s, est. speed input: 161.30 toks/s, output: 71.69 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: al of France? (Provide a specific example of a famous landmark in Paris to clarify the intent)\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "prompt: Define if the sentence entails the question.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████████████████████████| 1/1 [00:00<00:00,  2.88it/s, est. speed input: 161.29 toks/s, output: 72.00 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: sentence logically supports the question, using examples to clarify any ambiguity and restructure the sentence for clarity.\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "prompt: Summarize the following text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████████████████████████| 1/1 [00:00<00:00,  3.13it/s, est. speed input: 172.21 toks/s, output: 72.02 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: ense the text, providing clear examples, removing any ambiguity, and maintaining the original intent.\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "prompt: Please perform Sentiment Classification task.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████████████████████████| 1/1 [00:00<00:00,  1.73it/s, est. speed input: 95.20 toks/s, output: 74.43 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result:  Classification task by structuring the input, providing specific examples, removing ambiguity, and keeping the intent clear. Example: Classify the sentiment of the sentence \"I love this product!\" as positive.\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "prompt: Classify this sentence based on the provided categories.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████████████████████████| 1/1 [00:00<00:00,  2.28it/s, est. speed input: 132.28 toks/s, output: 72.98 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: ence into the given categories by applying transformations such as restructuring, adding specifics, removing ambiguity, providing an example, and maintaining the original intent.\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "prompt: Identify the most suitable category for this question.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████████████████████████| 1/1 [00:00<00:00,  2.76it/s, est. speed input: 160.38 toks/s, output: 71.89 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: stion into a clear, specific category by rephrasing it and providing an example, while maintaining the original intent.\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for prompt in prompts:\n",
    "    print(f\"prompt: {prompt}\")\n",
    "    print(f\"result: {pt.run(start_prompt=prompt)}\")\n",
    "    print(\"%\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a122665b-fc42-4ce3-af3c-5e5b5d0f6e43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
