{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом ноутбуке идет адаптация UniPrompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Клонируем репозиторий;\n",
    "Переходим в нужную директорию;\n",
    "Устанавливаем нужные библиотеки;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/TezzaTochka/AdaptationUniPrompt.git\n",
    "cd AdaptationUniPrompt/\n",
    "!python3 -m pip install --upgrade pip setuptools\n",
    "!python3 -m pip install .\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем нужные библиотеки;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uniprompt.beam_search import BeamSearch\n",
    "from uniprompt.data import create_ethos_dataset, load_data\n",
    "from uniprompt.evaluate import evaluate\n",
    "from uniprompt.grouping import Grouping\n",
    "from uniprompt.train import train\n",
    "\n",
    "from uniprompt.utils.config_utils import load_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скачиваем конфиг, который перед этим нужно было правильно настроить; Выгружаем выборки данных относительно информации из конфига;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-14T22:12:09.977555Z",
     "iopub.status.busy": "2025-08-14T22:12:09.976809Z",
     "iopub.status.idle": "2025-08-14T22:12:09.985837Z",
     "shell.execute_reply": "2025-08-14T22:12:09.985041Z",
     "shell.execute_reply.started": "2025-08-14T22:12:09.977527Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "config = load_config(\"config/ethos.json\")\n",
    "train_data, val_data, test_data = load_data(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поочередно инициализируем гиперпараметры метода относительно информации из конфига;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-14T22:12:12.024016Z",
     "iopub.status.busy": "2025-08-14T22:12:12.023195Z",
     "iopub.status.idle": "2025-08-14T22:12:12.027929Z",
     "shell.execute_reply": "2025-08-14T22:12:12.027147Z",
     "shell.execute_reply.started": "2025-08-14T22:12:12.023988Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Initialize UniPrompt\n",
    "beam = BeamSearch(config[\"beam_width\"])\n",
    "if \"number_of_groups\" in config:\n",
    "    number_of_groups = config[\"number_of_groups\"]\n",
    "else:\n",
    "    number_of_groups = 1\n",
    "\n",
    "grouping = Grouping(number_of_groups)\n",
    "p = config[\"initial_prompt\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Замеряем метрики качества на начальном промпте;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = evaluate(data=test_data, prompt=p, config = config)\n",
    "print(f\"Metrics for initial prompt: {p}: {metrics}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавляем во множество обработанных промптов начальный промпт;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize candidates\n",
    "beam.initialize_candidates(initial_prompt = p, data=val_data, config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запускаем саму оптимизацию промпта;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(config[\"epochs\"]):\n",
    "    # Create groups based on configured frequency\n",
    "    p = beam.get_best_prompt()\n",
    "    if epoch % config[\"group_frequency\"] == 0:\n",
    "        # if you want to group every epoch then you can do that or you can group based on the grouping frequency set in config\n",
    "        # grouping function is optional, you can provide your own grouping function\n",
    "        grouping.create_groups(prompt=p, data=train_data, config=config)\n",
    "\n",
    "    # Training iterations\n",
    "    for _ in range(config[\"iterations\"]):\n",
    "        print(f'Training start: {config[\"iterations\"]}')\n",
    "        beam = train(train_data=train_data, val_data=val_data, config=config, beam=beam, grouping = grouping)\n",
    "        p = beam.get_best_prompt()\n",
    "        # evaluation function is optional, you can provide your own evaluation function\n",
    "        metrics = evaluate(data=test_data, prompt=p, config = config)\n",
    "        print(f\"Epoch: {epoch}, Prompt: {p}, Metrics: {metrics}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Смотрим и сравниваем результаты оптимизации;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final evaluation\n",
    "p = beam.get_best_prompt()\n",
    "final_metrics = evaluate(data=test_data, prompt=p, config = config)\n",
    "\n",
    "print(f\"Best prompt: {p}\")\n",
    "print(f\"Final metrics: {final_metrics}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
