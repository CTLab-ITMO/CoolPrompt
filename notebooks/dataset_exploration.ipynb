{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78b99ba59c4562a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T15:25:38.356410200Z",
     "start_time": "2025-03-20T15:25:22.892322400Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f3574140e50>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "# This code enables using of \"src.data\" imports in vs code (when you're launching it directly from notebooks directory)\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"../../\"))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Loading model weights\n",
    "\n",
    "model_name = \"AnatoliiPotapov/T-lite-instruct-0.1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, padding_side='left')\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1009dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b1b8b8b44f0f660c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bd9e6f293f2e57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T15:53:06.884313200Z",
     "start_time": "2025-03-20T15:52:59.950102700Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MathDataset\n",
      "Solve the math word problem\n",
      "\n",
      "INPUT:\n",
      "<INPUT>\n",
      "\n",
      "RESPONSE:\n",
      "\n",
      "Min label length is 0 with label: \n",
      "Median label length is 1.0\n",
      "Max label length is 87 with label: \\begin{pmatrix} \\frac{4}{9} & -\\frac{4}{9} & -\\frac{2}{9} \\\\ -\\frac{4}{9} & \\frac{4}{9} & \\frac{2}{9} \\\\ -\\frac{2}{9} & \\frac{2}{9} & \\frac{1}{9} \\end{pmatrix}\n",
      "-------------------------------------------------------------\n",
      "GSM8KDataset\n",
      "Solve the math word problem, giving your answer as an arabic numeral.\n",
      "\n",
      "INPUT:\n",
      "<INPUT>\n",
      "\n",
      "RESPONSE:\n",
      "\n",
      "Min label length is 1 with label: 72\n",
      "Median label length is 1.0\n",
      "Max label length is 3 with label: 192000000\n",
      "-------------------------------------------------------------\n",
      "SamsumDataset\n",
      "Summarize the following text\n",
      "\n",
      "INPUT:\n",
      "<INPUT>\n",
      "\n",
      "RESPONSE:\n",
      "\n",
      "Min label length is 1 with label: test\n",
      "Median label length is 23.0\n",
      "Max label length is 84 with label: Mousie told Joddie about the attack on Paweł Adamowicz, the President of Gdańsk, during Jurek Owsiak's Wielka Orkiestra concert. She is convinced that the ruling party Prawo i Sprawiedliwość and its leader Jarosław Kaczyński are to blame for the attack because of their hateful conservative views.\n",
      "-------------------------------------------------------------\n",
      "MedQADataset\n",
      "Please use your domain knowledge in medical area to solve the questions.\n",
      "\n",
      "Answer using the label from [A, B, C, D, E].\n",
      "Generate the final answer bracketed with <ans> and </ans>.\n",
      "\n",
      "The input:\n",
      "<INPUT>\n",
      "\n",
      "Response:\n",
      "\n",
      "Min label length is 1 with label: %\n",
      "Median label length is 1.0\n",
      "Max label length is 1 with label: %\n",
      "-------------------------------------------------------------\n",
      "OpenbookQADataset\n",
      "Answer the following question: \n",
      "\n",
      "Answer using the label from [A, B, C, D].\n",
      "Generate the final answer bracketed with <ans> and </ans>.\n",
      "\n",
      "The input:\n",
      "<INPUT>\n",
      "\n",
      "Response:\n",
      "\n",
      "Min label length is 1 with label: $\n",
      "Median label length is 1.0\n",
      "Max label length is 1 with label: $\n",
      "-------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "project_root = os.path.abspath('/nfs/home/edyagin/CoolPrompt/')\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from src.data.generation import gsm8k_dataset, math_dataset, samsum_dataset\n",
    "from src.data.qa import medqa_dataset, openbookqa_dataset\n",
    "\n",
    "\n",
    "gen_datasets = [\n",
    "    math_dataset.MathDataset, \n",
    "    gsm8k_dataset.GSM8KDataset, \n",
    "    samsum_dataset.SamsumDataset,\n",
    "    medqa_dataset.MedQADataset,\n",
    "    openbookqa_dataset.OpenbookQADataset\n",
    "]\n",
    "\n",
    "ds_to_mx = {}\n",
    "\n",
    "for ds in gen_datasets:\n",
    "    train_set = ds(tokenizer, split='train')\n",
    "    test_set = ds(tokenizer, split='test')\n",
    "    \n",
    "    print(ds.__name__)\n",
    "    print(train_set.prompt)\n",
    "    \n",
    "    full_ds = torch.utils.data.ConcatDataset([train_set, test_set])\n",
    "    label_tokens = [label_id for _, _, label_id in full_ds]\n",
    "    labels_unpadded = tokenizer.batch_decode(label_tokens, skip_special_tokens=True)\n",
    "    label_tokens_unpadded = tokenizer(labels_unpadded)['input_ids']\n",
    "    \n",
    "    label_sizes = np.array([len(token) for token in label_tokens_unpadded])\n",
    "    \n",
    "    min_size = np.min(label_sizes)\n",
    "    median_size = np.percentile(label_sizes, 50)\n",
    "    max_size = np.max(label_sizes)\n",
    "    \n",
    "    min_idx = np.argmin(label_sizes)\n",
    "    max_idx = np.argmax(label_sizes)\n",
    "    \n",
    "    ds_to_mx[ds.__name__] = max_size\n",
    "    \n",
    "    print(f\"Min label length is {min_size} with label: {tokenizer.decode(label_tokens[min_idx], skip_special_tokens=True)}\")\n",
    "    print(\"Median label length is\", median_size)\n",
    "    print(f\"Max label length is {max_size} with label: {tokenizer.decode(label_tokens[max_idx], skip_special_tokens=True)}\")\n",
    "    print(\"-------------------------------------------------------------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9d44010f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MathDataset': 87,\n",
       " 'GSM8KDataset': 3,\n",
       " 'SamsumDataset': 84,\n",
       " 'MedQADataset': 1,\n",
       " 'OpenbookQADataset': 1}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_to_mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "69bd7a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_sorting\n",
      "Sort a list of words.\n",
      "\n",
      "INPUT:\n",
      "<INPUT>\n",
      "\n",
      "RESPONSE:\n",
      "\n",
      "Min label length is 3 with label: beth kenya\n",
      "Median label length is 22.5\n",
      "Max label length is 49 with label: aeneas colombo foothold fox garry glycerine inviolate lucre magnanimity nevada notoriety plebiscite pompey quagmire satanic scription softball spleenwort tennyson type\n",
      "-------------------------------------------------------------\n",
      "object_counting\n",
      "Questions that involve enumerating objects and asking the model to count them.\n",
      "\n",
      "INPUT:\n",
      "<INPUT>\n",
      "\n",
      "RESPONSE:\n",
      "\n",
      "Min label length is 1 with label: 7\n",
      "Median label length is 1.0\n",
      "Max label length is 1 with label: 7\n",
      "-------------------------------------------------------------\n",
      "dyck_languages\n",
      " Correctly close a Dyck-n word.\n",
      "\n",
      "INPUT:\n",
      "<INPUT>\n",
      "\n",
      "RESPONSE:\n",
      "\n",
      "Min label length is 1 with label: ]\n",
      "Median label length is 2.0\n",
      "Max label length is 3 with label: } ) >\n",
      "-------------------------------------------------------------\n",
      "multistep_arithmetic_two\n",
      "Solve multi-step arithmetic problems.\n",
      "\n",
      "INPUT:\n",
      "<INPUT>\n",
      "\n",
      "RESPONSE:\n",
      "\n",
      "Min label length is 1 with label: 70\n",
      "Median label length is 2.0\n",
      "Max label length is 3 with label: -2146\n",
      "-------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from src.data.multi_task import BBHDataset\n",
    "\n",
    "BBH_GENERATION_TASKS = set([\n",
    "    'dyck_languages',\n",
    "    'multistep_arithmetic_two',\n",
    "    'object_counting',\n",
    "    'word_sorting'\n",
    "])\n",
    "\n",
    "ds_to_mx = {}\n",
    "\n",
    "for task in BBH_GENERATION_TASKS:\n",
    "    train_set = BBHDataset(tokenizer, split='train').task(task)\n",
    "    test_set = BBHDataset(tokenizer, split='test').task(task)\n",
    "    \n",
    "    print(task)\n",
    "    print(train_set.prompt)\n",
    "    \n",
    "    full_ds = torch.utils.data.ConcatDataset([train_set, test_set])\n",
    "    label_tokens = [label_id for _, _, label_id in full_ds]\n",
    "    labels_unpadded = tokenizer.batch_decode(label_tokens, skip_special_tokens=True)\n",
    "    label_tokens_unpadded = tokenizer(labels_unpadded)['input_ids']\n",
    "    \n",
    "    label_sizes = np.array([len(token) for token in label_tokens_unpadded])\n",
    "    \n",
    "    min_size = np.min(label_sizes)\n",
    "    median_size = np.percentile(label_sizes, 50)\n",
    "    max_size = np.max(label_sizes)\n",
    "    \n",
    "    min_idx = np.argmin(label_sizes)\n",
    "    max_idx = np.argmax(label_sizes)\n",
    "    \n",
    "    ds_to_mx[task] = max_size\n",
    "    \n",
    "    print(f\"Min label length is {min_size} with label: {tokenizer.decode(label_tokens[min_idx], skip_special_tokens=True)}\")\n",
    "    print(\"Median label length is\", median_size)\n",
    "    print(f\"Max label length is {max_size} with label: {tokenizer.decode(label_tokens[max_idx], skip_special_tokens=True)}\")\n",
    "    print(\"-------------------------------------------------------------\")\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8d67133c8e8fca73",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'word_sorting': 49,\n",
       " 'object_counting': 1,\n",
       " 'dyck_languages': 3,\n",
       " 'multistep_arithmetic_two': 3}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_to_mx"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prompt_optimization",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
